{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM Model Pipeline for HVAC Blueprint Analysis",
    "",
    "## Overview",
    "End-to-end pipeline for training SAM models on HVAC blueprints with 6 simplified component categories.",
    "",
    "**Author**: HVAC AI Development Team  ",
    "**Date**: 2025-12-06  ",
    "**Model**: SAM ViT-B optimized for Google Colab T4 GPU",
    "",
    "### Simplified Categories:",
    "1. Equipment (pumps, coils, fans, motors, compressors, tanks)",
    "2. Ductwork (ducts, bends, reducers)",
    "3. Piping (insulated pipes, traps)",
    "4. Valves (all valve types consolidated)",
    "5. Air Devices (dampers, filters, detectors)",
    "6. Controls (sensors, switches, instrumentation)",
    "",
    "### Pipeline Phases:",
    "- Phase 1: Environment Setup",
    "- Phase 2: Dataset Loading & Class Consolidation",
    "- Phase 3: Quality Audit & Image Selection",
    "- Phase 4: Prompt Engineering System",
    "- Phase 5: Model Training & Fine-tuning",
    "- Phase 6: Inference Pipeline",
    "- Phase 7: Model Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SAM and dependencies",
    "!pip install -q git+https://github.com/facebookresearch/segment-anything.git",
    "!pip install -q torch torchvision opencv-python-headless pycocotools albumentations tqdm",
    "!pip install -q matplotlib pillow numpy pandas scikit-learn scipy",
    "",
    "print(\"\u2713 Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os",
    "import sys",
    "import json",
    "import logging",
    "from pathlib import Path",
    "from typing import Dict, List, Tuple, Optional, Any",
    "from dataclasses import dataclass",
    "from collections import defaultdict, Counter",
    "import random",
    "import warnings",
    "",
    "import numpy as np",
    "import pandas as pd",
    "import cv2",
    "from PIL import Image",
    "import matplotlib.pyplot as plt",
    "",
    "import torch",
    "import torch.nn as nn",
    "from torch.utils.data import Dataset, DataLoader",
    "from torch.amp import autocast, GradScaler",
    "",
    "from segment_anything import sam_model_registry, SamPredictor",
    "from tqdm.auto import tqdm",
    "",
    "warnings.filterwarnings('ignore')",
    "",
    "# Reproducibility",
    "SEED = 42",
    "random.seed(SEED)",
    "np.random.seed(SEED)",
    "torch.manual_seed(SEED)",
    "",
    "# GPU Setup",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
    "print(f\"Device: {device}\")",
    "if torch.cuda.is_available():",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")",
    "",
    "# Logging",
    "logging.basicConfig(level=logging.INFO)",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Dataset Loading & Class Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping to 6 simplified classes",
    "CATEGORY_MAPPING = {",
    "    \"Equipment\": [\"centrifugal-pump\", \"Coil\", \"coil\", \"Fan\", \"fan\", \"e_motor_3p\", ",
    "                  \"scroll_compressosr\", \"tank\", \"finned_tubes_HE\", \"cooling coil\", ",
    "                  \"heating coil\", \"exhaust-air-fan\", \"supply-air-fan\"],",
    "    \"Ductwork\": [\"duct\", \"bend\", \"reducer\"],",
    "    \"Piping\": [\"Pipe-Insulated\", \"insulated_pipe\", \"insulation_pipe\", \"u_trap\"],",
    "    \"Valves\": [\"ball w insulate\", \"ball_valve_with_schrader\", \"BDV\", \"SDV\",",
    "               \"Valve-Ball\", \"Ball Valve\", \"ball-valve\", \"ball_valve\",",
    "               \"Valve-Butterfly\", \"butterfly valve\", \"butterfly-valve\",",
    "               \"Valve-Check\", \"Check Valve\", \"check valve\", \"check-valve\",",
    "               \"Valve-Control\", \"FCV\", \"LCV\", \"PCV\", \"TCV\", \"control valve\",",
    "               \"Valve-Gate\", \"Gate Valve\", \"gate valve\", \"gate-valve\",",
    "               \"Valve-Globe\", \"Globe Valve\", \"GlobalValve\", \"globe valve\",",
    "               \"Valve-Needle\", \"Needle Valve\", \"needle_valve\",",
    "               \"Valve-SafetyRelief\", \"PSV\", \"press_relief_val\",",
    "               \"Valve-ThreeWay\", \"three way valve\", \"three_way_valve\",",
    "               \"Plug Valve\", \"ex_valve\", \"Piston Operated Control Valve\"],",
    "    \"Air Devices\": [\"Damper\", \"fire-damper\", \"Filter\", \"fire-detector\", \"smoke detector\",",
    "                    \"exhaust air damp\", \"mixed-air-damp\", \"outside-air-damper\",",
    "                    \"extract-air-filter\", \"outside-air-filter\", \"main_filter\", \"pre_filter\"],",
    "    \"Controls\": [\"maintainance-switch\", \"pressure sensor\", \"Sensor-Temperature\",",
    "                 \"sight_glass\", \"solenoid_valve\", \"filter_drier\", \"vd\",",
    "                 \"schraeder_vavle\", \"air temp sensor\", \"room temp sensor\", \"temperature-sensor\"]",
    "}",
    "",
    "# Reverse mapping",
    "REVERSE_MAP = {}",
    "for simp, origs in CATEGORY_MAPPING.items():",
    "    for orig in origs:",
    "        REVERSE_MAP[orig.lower()] = simp",
    "        REVERSE_MAP[orig] = simp",
    "",
    "SIMP_CATEGORIES = {i: name for i, name in enumerate(CATEGORY_MAPPING.keys())}",
    "print(f\"Simplified categories: {SIMP_CATEGORIES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths (adjust for your environment)",
    "DATASET_ROOT = \"/content/datasets\"  # Change if needed",
    "SPLITS = {\" train\": \"train\", \"valid\": \"valid\", \"test\": \"test\"}",
    "",
    "# Check dataset",
    "if not os.path.exists(DATASET_ROOT):",
    "    print(f\"\u26a0\ufe0f Dataset not found at {DATASET_ROOT}\")",
    "    print(\"Please upload and extract hvac-dataset.zip\")",
    "else:",
    "    for split_name, split_dir in SPLITS.items():",
    "        split_path = os.path.join(DATASET_ROOT, split_dir)",
    "        if os.path.exists(split_path):",
    "            ann_file = os.path.join(split_path, \"_annotations.coco.json\")",
    "            if os.path.exists(ann_file):",
    "                with open(ann_file) as f:",
    "                    data = json.load(f)",
    "                print(f\"\u2713 {split_name}: {len(data['images'])} images, {len(data['annotations'])} annotations\")",
    "            else:",
    "                print(f\"\u26a0\ufe0f {split_name}: annotations not found\")",
    "        else:",
    "            print(f\"\u26a0\ufe0f {split_name}: directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOHandler:",
    "    '''Handle COCO dataset loading and category mapping'''",
    "    ",
    "    def __init__(self, split_dir: str):",
    "        self.split_dir = Path(split_dir)",
    "        self.ann_file = self.split_dir / \"_annotations.coco.json\"",
    "        ",
    "        with open(self.ann_file) as f:",
    "            self.coco = json.load(f)",
    "        ",
    "        self.images = {img['id']: img for img in self.coco['images']}",
    "        self.anns_by_image = defaultdict(list)",
    "        for ann in self.coco['annotations']:",
    "            self.anns_by_image[ann['image_id']].append(ann)",
    "        ",
    "        logger.info(f\"Loaded {len(self.images)} images from {split_dir}\")",
    "    ",
    "    def get_category_name(self, cat_id: int) -> str:",
    "        for cat in self.coco['categories']:",
    "            if cat['id'] == cat_id:",
    "                return cat['name']",
    "        return \"unknown\"",
    "    ",
    "    def map_to_simplified(self, orig_name: str) -> Optional[str]:",
    "        '''Map original category to simplified'''",
    "        key = orig_name.lower().strip()",
    "        return REVERSE_MAP.get(key, REVERSE_MAP.get(orig_name))",
    "    ",
    "    def get_image_path(self, img_id: int) -> Path:",
    "        return self.split_dir / self.images[img_id]['file_name']",
    "    ",
    "    def get_annotations(self, img_id: int) -> List[Dict]:",
    "        return self.anns_by_image.get(img_id, [])",
    "",
    "# Test loading",
    "try:",
    "    train_handler = COCOHandler(os.path.join(DATASET_ROOT, \"train\"))",
    "    print(f\"\u2713 Train handler created: {len(train_handler.images)} images\")",
    "except Exception as e:",
    "    print(f\"\u26a0\ufe0f Could not load train split: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Quality Audit & Image Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityAuditor:",
    "    '''Audit dataset quality and select best images'''",
    "    ",
    "    def __init__(self, handler: COCOHandler):",
    "        self.handler = handler",
    "        self.metrics = {}",
    "    ",
    "    def compute_image_quality(self, img_path: Path) -> Dict[str, float]:",
    "        '''Compute quality metrics for image'''",
    "        try:",
    "            img = cv2.imread(str(img_path))",
    "            if img is None:",
    "                return {'overall': 0.0}",
    "            ",
    "            h, w = img.shape[:2]",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)",
    "            ",
    "            # Resolution score",
    "            megapixels = (h * w) / 1_000_000",
    "            res_score = min(megapixels / 2.0, 1.0)",
    "            ",
    "            # Contrast score",
    "            contrast = np.std(gray) / 60.0",
    "            contrast_score = min(contrast, 1.0)",
    "            ",
    "            # Sharpness score",
    "            laplacian = cv2.Laplacian(gray, cv2.CV_64F)",
    "            sharpness = min(laplacian.var() / 500.0, 1.0)",
    "            ",
    "            overall = (res_score + contrast_score + sharpness) / 3.0",
    "            ",
    "            return {",
    "                'resolution': res_score,",
    "                'contrast': contrast_score,",
    "                'sharpness': sharpness,",
    "                'overall': overall",
    "            }",
    "        except Exception as e:",
    "            logger.warning(f\"Error processing {img_path}: {e}\")",
    "            return {'overall': 0.0}",
    "    ",
    "    def compute_annotation_quality(self, img_id: int) -> Dict[str, float]:",
    "        '''Compute annotation quality for image'''",
    "        anns = self.handler.get_annotations(img_id)",
    "        ",
    "        if not anns:",
    "            return {'overall': 0.0}",
    "        ",
    "        valid = 0",
    "        categories = set()",
    "        ",
    "        for ann in anns:",
    "            orig_name = self.handler.get_category_name(ann['category_id'])",
    "            if self.handler.map_to_simplified(orig_name):",
    "                valid += 1",
    "                categories.add(self.handler.map_to_simplified(orig_name))",
    "        ",
    "        completeness = valid / len(anns) if anns else 0.0",
    "        diversity = len(categories) / 6.0",
    "        density = valid / max(len(anns), 1)",
    "        ",
    "        overall = (completeness + diversity + density) / 3.0",
    "        ",
    "        return {",
    "            'completeness': completeness,",
    "            'diversity': diversity,",
    "            'density': density,",
    "            'overall': overall",
    "        }",
    "    ",
    "    def audit_images(self, max_images: Optional[int] = None):",
    "        '''Audit all or subset of images'''",
    "        img_ids = list(self.handler.images.keys())",
    "        if max_images:",
    "            img_ids = img_ids[:max_images]",
    "        ",
    "        for img_id in tqdm(img_ids, desc=\"Auditing\"):",
    "            img_path = self.handler.get_image_path(img_id)",
    "            ",
    "            img_qual = self.compute_image_quality(img_path)",
    "            ann_qual = self.compute_annotation_quality(img_id)",
    "            ",
    "            overall_score = (img_qual['overall'] + ann_qual['overall']) / 2.0",
    "            ",
    "            self.metrics[img_id] = {",
    "                'image_quality': img_qual,",
    "                'annotation_quality': ann_qual,",
    "                'overall_score': overall_score",
    "            }",
    "        ",
    "        logger.info(f\"Audit complete: {len(self.metrics)} images\")",
    "    ",
    "    def select_top_quality(self, percentile: float = 30.0) -> List[int]:",
    "        '''Select top percentile of images'''",
    "        sorted_imgs = sorted(",
    "            self.metrics.items(),",
    "            key=lambda x: x[1]['overall_score'],",
    "            reverse=True",
    "        )",
    "        ",
    "        n_select = int(len(sorted_imgs) * (percentile / 100.0))",
    "        selected = [img_id for img_id, _ in sorted_imgs[:n_select]]",
    "        ",
    "        logger.info(f\"Selected top {percentile}%: {len(selected)} images\")",
    "        return selected",
    "    ",
    "    def get_stats(self) -> pd.DataFrame:",
    "        '''Get quality statistics'''",
    "        data = []",
    "        for img_id, metrics in self.metrics.items():",
    "            data.append({",
    "                'image_id': img_id,",
    "                'image_quality': metrics['image_quality']['overall'],",
    "                'annotation_quality': metrics['annotation_quality']['overall'],",
    "                'overall_score': metrics['overall_score']",
    "            })",
    "        return pd.DataFrame(data).describe()",
    "",
    "# Run audit",
    "if 'train_handler' in locals():",
    "    print(\"Running quality audit...\")",
    "    auditor = QualityAuditor(train_handler)",
    "    auditor.audit_images(max_images=100)  # Audit first 100 for demo",
    "    print(auditor.get_stats())",
    "    ",
    "    top_images = auditor.select_top_quality(percentile=30.0)",
    "    print(f\"\\nSelected {len(top_images)} high-quality images\")",
    "else:",
    "    print(\"\u26a0\ufe0f Train handler not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Comprehensive Prompt Engineering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptEngineer:",
    "    '''Advanced prompt engineering for HVAC blueprint analysis'''",
    "    ",
    "    def __init__(self):",
    "        self.category_prompts = self._build_category_prompts()",
    "        self.contextual_prompts = self._build_contextual_prompts()",
    "    ",
    "    def _build_category_prompts(self) -> Dict[str, List[str]]:",
    "        '''Build category-specific prompt templates'''",
    "        return {",
    "            \"Equipment\": [",
    "                \"HVAC equipment in technical drawing\",",
    "                \"Mechanical equipment component in blueprint\",",
    "                \"Pump, fan, or coil in HVAC diagram\",",
    "                \"Major HVAC system equipment\"",
    "            ],",
    "            \"Ductwork\": [",
    "                \"Ductwork in HVAC blueprint\",",
    "                \"Air duct system component\",",
    "                \"Duct section in mechanical drawing\",",
    "                \"Ventilation ductwork element\"",
    "            ],",
    "            \"Piping\": [",
    "                \"Piping in HVAC system\",",
    "                \"Insulated pipe in blueprint\",",
    "                \"Pipe section in mechanical diagram\",",
    "                \"HVAC piping component\"",
    "            ],",
    "            \"Valves\": [",
    "                \"Valve in HVAC system\",",
    "                \"Control valve in blueprint\",",
    "                \"Valve symbol in mechanical drawing\",",
    "                \"HVAC valve component\"",
    "            ],",
    "            \"Air Devices\": [",
    "                \"Air handling device in blueprint\",",
    "                \"Damper or filter in HVAC system\",",
    "                \"Air device in mechanical drawing\",",
    "                \"Ventilation component\"",
    "            ],",
    "            \"Controls\": [",
    "                \"Control device in HVAC system\",",
    "                \"Sensor or switch in blueprint\",",
    "                \"Instrumentation in mechanical drawing\",",
    "                \"HVAC control component\"",
    "            ]",
    "        }",
    "    ",
    "    def _build_contextual_prompts(self) -> List[str]:",
    "        '''Build contextual prompts for spatial relationships'''",
    "        return [",
    "            \"Component in HVAC system layout\",",
    "            \"Equipment in technical blueprint\",",
    "            \"Mechanical system component\",",
    "            \"HVAC element in drawing\",",
    "            \"Technical diagram component\"",
    "        ]",
    "    ",
    "    def get_prompts_for_category(self, category: str) -> List[str]:",
    "        '''Get prompts for specific category'''",
    "        return self.category_prompts.get(category, self.contextual_prompts)",
    "    ",
    "    def get_hierarchical_prompts(",
    "        self,",
    "        category: str,",
    "        confidence: float = 1.0",
    "    ) -> List[str]:",
    "        '''Get hierarchical prompts based on confidence'''",
    "        prompts = []",
    "        ",
    "        if confidence > 0.8:",
    "            # High confidence: use specific prompts",
    "            prompts = self.get_prompts_for_category(category)[:2]",
    "        elif confidence > 0.5:",
    "            # Medium confidence: use more general prompts",
    "            prompts = self.get_prompts_for_category(category)[1:3]",
    "        else:",
    "            # Low confidence: use contextual prompts",
    "            prompts = self.contextual_prompts[:2]",
    "        ",
    "        return prompts",
    "    ",
    "    def get_fallback_prompts(self) -> List[str]:",
    "        '''Get fallback prompts for difficult cases'''",
    "        return [",
    "            \"Object in technical drawing\",",
    "            \"Component in blueprint\",",
    "            \"Element in mechanical diagram\"",
    "        ]",
    "",
    "# Initialize prompt engineer",
    "prompt_engineer = PromptEngineer()",
    "print(\"\u2713 Prompt engineering system initialized\")",
    "",
    "# Test prompts",
    "for category in CATEGORY_MAPPING.keys():",
    "    prompts = prompt_engineer.get_prompts_for_category(category)",
    "    print(f\"\\n{category}: {len(prompts)} prompts\")",
    "    print(f\"  Example: '{prompts[0]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Dataset and Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HVACDataset(Dataset):",
    "    '''PyTorch Dataset for HVAC blueprint segmentation'''",
    "    ",
    "    def __init__(",
    "        self,",
    "        handler: COCOHandler,",
    "        image_ids: List[int],",
    "        transform=None",
    "    ):",
    "        self.handler = handler",
    "        self.image_ids = image_ids",
    "        self.transform = transform",
    "    ",
    "    def __len__(self) -> int:",
    "        return len(self.image_ids)",
    "    ",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:",
    "        img_id = self.image_ids[idx]",
    "        ",
    "        # Load image",
    "        img_path = self.handler.get_image_path(img_id)",
    "        image = cv2.imread(str(img_path))",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)",
    "        ",
    "        # Get annotations",
    "        anns = self.handler.get_annotations(img_id)",
    "        ",
    "        # Process annotations",
    "        masks = []",
    "        categories = []",
    "        boxes = []",
    "        ",
    "        for ann in anns:",
    "            # Map to simplified category",
    "            orig_name = self.handler.get_category_name(ann['category_id'])",
    "            simp_cat = self.handler.map_to_simplified(orig_name)",
    "            ",
    "            if simp_cat and 'bbox' in ann:",
    "                # Get category ID",
    "                cat_id = list(CATEGORY_MAPPING.keys()).index(simp_cat)",
    "                categories.append(cat_id)",
    "                ",
    "                # Convert bbox [x, y, w, h] to [x1, y1, x2, y2]",
    "                x, y, w, h = ann['bbox']",
    "                boxes.append([x, y, x + w, y + h])",
    "                ",
    "                # Process segmentation mask",
    "                if 'segmentation' in ann:",
    "                    # Create binary mask from segmentation",
    "                    mask = np.zeros(image.shape[:2], dtype=np.uint8)",
    "                    if isinstance(ann['segmentation'], list):",
    "                        for seg in ann['segmentation']:",
    "                            if isinstance(seg, list) and len(seg) > 0:",
    "                                pts = np.array(seg).reshape(-1, 2).astype(np.int32)",
    "                                cv2.fillPoly(mask, [pts], 1)",
    "                    masks.append(mask)",
    "                else:",
    "                    # Use bounding box as mask",
    "                    mask = np.zeros(image.shape[:2], dtype=np.uint8)",
    "                    mask[int(y):int(y+h), int(x):int(x+w)] = 1",
    "                    masks.append(mask)",
    "        ",
    "        return {",
    "            'image': image,",
    "            'masks': np.array(masks) if masks else np.zeros((0, *image.shape[:2])),",
    "            'boxes': np.array(boxes) if boxes else np.zeros((0, 4)),",
    "            'categories': np.array(categories) if categories else np.array([]),",
    "            'image_id': img_id",
    "        }",
    "",
    "print(\"\u2713 Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration",
    "@dataclass",
    "class TrainingConfig:",
    "    batch_size: int = 1",
    "    num_epochs: int = 20",
    "    learning_rate: float = 1e-4",
    "    weight_decay: float = 1e-4",
    "    mixed_precision: bool = True",
    "    gradient_accumulation_steps: int = 4",
    "    checkpoint_freq: int = 5",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"",
    "",
    "config = TrainingConfig()",
    "print(f\"Training config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMFineTuner:",
    "    '''Fine-tune SAM model for HVAC blueprints'''",
    "    ",
    "    def __init__(self, config: TrainingConfig):",
    "        self.config = config",
    "        self.device = torch.device(config.device)",
    "        ",
    "        # Load SAM model",
    "        print(\"Loading SAM model...\")",
    "        model_type = \"vit_b\"",
    "        checkpoint = \"sam_vit_b_01ec64.pth\"",
    "        ",
    "        # Download checkpoint if needed",
    "        if not os.path.exists(checkpoint):",
    "            print(f\"Downloading {checkpoint}...\")",
    "            !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth",
    "        ",
    "        self.model = sam_model_registry[model_type](checkpoint=checkpoint)",
    "        self.model.to(self.device)",
    "        ",
    "        # Freeze image encoder",
    "        for param in self.model.image_encoder.parameters():",
    "            param.requires_grad = False",
    "        ",
    "        # Only train mask decoder",
    "        for param in self.model.mask_decoder.parameters():",
    "            param.requires_grad = True",
    "        ",
    "        print(f\"\u2713 SAM model loaded on {self.device}\")",
    "        ",
    "        # Setup optimizer",
    "        self.optimizer = torch.optim.AdamW(",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),",
    "            lr=config.learning_rate,",
    "            weight_decay=config.weight_decay",
    "        )",
    "        ",
    "        # Mixed precision scaler",
    "        self.scaler = GradScaler() if config.mixed_precision else None",
    "    ",
    "    def train_step(self, batch: Dict[str, Any]) -> float:",
    "        '''Single training step'''",
    "        self.model.train()",
    "        ",
    "        images = batch['image'].to(self.device)",
    "        masks_gt = batch['masks'].to(self.device)",
    "        boxes = batch['boxes'].to(self.device)",
    "        ",
    "        # Forward pass",
    "        with autocast(device_type='cuda', enabled=self.config.mixed_precision):",
    "            # Get image embeddings",
    "            image_embeddings = self.model.image_encoder(images)",
    "            ",
    "            # Predict masks",
    "            sparse_embeddings, dense_embeddings = self.model.prompt_encoder(",
    "                points=None,",
    "                boxes=boxes,",
    "                masks=None",
    "            )",
    "            ",
    "            masks_pred, iou_pred = self.model.mask_decoder(",
    "                image_embeddings=image_embeddings,",
    "                image_pe=self.model.prompt_encoder.get_dense_pe(),",
    "                sparse_prompt_embeddings=sparse_embeddings,",
    "                dense_prompt_embeddings=dense_embeddings,",
    "                multimask_output=False",
    "            )",
    "            ",
    "            # Compute loss",
    "            loss = nn.functional.binary_cross_entropy_with_logits(",
    "                masks_pred, masks_gt",
    "            )",
    "        ",
    "        # Backward pass",
    "        if self.scaler:",
    "            self.scaler.scale(loss).backward()",
    "            self.scaler.step(self.optimizer)",
    "            self.scaler.update()",
    "        else:",
    "            loss.backward()",
    "            self.optimizer.step()",
    "        ",
    "        self.optimizer.zero_grad()",
    "        ",
    "        return loss.item()",
    "    ",
    "    def train(self, train_loader: DataLoader, num_epochs: int):",
    "        '''Training loop'''",
    "        for epoch in range(num_epochs):",
    "            epoch_loss = 0.0",
    "            ",
    "            pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")",
    "            for batch_idx, batch in enumerate(pbar):",
    "                loss = self.train_step(batch)",
    "                epoch_loss += loss",
    "                ",
    "                pbar.set_postfix({'loss': f'{loss:.4f}'})",
    "            ",
    "            avg_loss = epoch_loss / len(train_loader)",
    "            print(f\"\\nEpoch {epoch+1} - Avg Loss: {avg_loss:.4f}\")",
    "            ",
    "            # Save checkpoint",
    "            if (epoch + 1) % self.config.checkpoint_freq == 0:",
    "                self.save_checkpoint(f\"checkpoint_epoch_{epoch+1}.pth\")",
    "    ",
    "    def save_checkpoint(self, filename: str):",
    "        '''Save model checkpoint'''",
    "        torch.save({",
    "            'model_state_dict': self.model.state_dict(),",
    "            'optimizer_state_dict': self.optimizer.state_dict(),",
    "        }, filename)",
    "        print(f\"\u2713 Checkpoint saved: {filename}\")",
    "",
    "print(\"\u2713 SAM fine-tuner defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HVACInference:",
    "    '''Inference pipeline for HVAC blueprint analysis'''",
    "    ",
    "    def __init__(self, model, device: str = \"cuda\"):",
    "        self.model = model",
    "        self.device = torch.device(device)",
    "        self.model.eval()",
    "        self.predictor = SamPredictor(model)",
    "        self.prompt_engineer = PromptEngineer()",
    "    ",
    "    def predict(",
    "        self,",
    "        image: np.ndarray,",
    "        boxes: Optional[np.ndarray] = None",
    "    ) -> Dict[str, Any]:",
    "        '''Run inference on image'''",
    "        with torch.no_grad():",
    "            # Set image",
    "            self.predictor.set_image(image)",
    "            ",
    "            if boxes is not None:",
    "                # Predict with box prompts",
    "                masks, scores, _ = self.predictor.predict(",
    "                    box=boxes,",
    "                    multimask_output=False",
    "                )",
    "                ",
    "                return {",
    "                    'masks': masks,",
    "                    'scores': scores",
    "                }",
    "            else:",
    "                # Full image segmentation",
    "                return self._segment_full_image(image)",
    "    ",
    "    def _segment_full_image(self, image: np.ndarray) -> Dict[str, Any]:",
    "        '''Segment entire image'''",
    "        # This would implement automatic component detection",
    "        # For now, return placeholder",
    "        return {",
    "            'masks': np.array([]),",
    "            'scores': np.array([]),",
    "            'categories': np.array([])",
    "        }",
    "    ",
    "    def visualize_results(",
    "        self,",
    "        image: np.ndarray,",
    "        masks: np.ndarray,",
    "        categories: Optional[List[int]] = None",
    "    ):",
    "        '''Visualize segmentation results'''",
    "        plt.figure(figsize=(12, 8))",
    "        plt.imshow(image)",
    "        ",
    "        if len(masks) > 0:",
    "            # Overlay masks",
    "            for i, mask in enumerate(masks):",
    "                color = plt.cm.tab10(i % 10)",
    "                plt.imshow(mask, alpha=0.3, cmap='Reds')",
    "                ",
    "                if categories:",
    "                    cat_name = SIMP_CATEGORIES[categories[i]]",
    "                    plt.text(10, 30 + i*20, cat_name, ",
    "                            color=color, fontsize=10,",
    "                            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))",
    "        ",
    "        plt.axis('off')",
    "        plt.title(\"HVAC Component Segmentation\")",
    "        plt.tight_layout()",
    "        plt.show()",
    "",
    "print(\"\u2713 Inference pipeline defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7: Model Export and Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(model, output_path: str = \"sam_hvac_final.pth\"):",
    "    '''Export trained model'''",
    "    torch.save({",
    "        'model_state_dict': model.state_dict(),",
    "        'config': {",
    "            'model_type': 'vit_b',",
    "            'num_categories': 6,",
    "            'categories': list(CATEGORY_MAPPING.keys())",
    "        }",
    "    }, output_path)",
    "    print(f\"\u2713 Model exported to {output_path}\")",
    "",
    "def create_model_card():",
    "    '''Create model documentation'''",
    "    card = f\"\"\"",
    "# SAM HVAC Blueprint Analysis Model",
    "",
    "## Model Overview",
    "- **Base Model**: SAM ViT-B",
    "- **Task**: HVAC component segmentation in blueprints",
    "- **Categories**: 6 simplified classes",
    "- **Training**: Fine-tuned mask decoder",
    "",
    "## Categories",
    "{chr(10).join(f'{i+1}. {name}' for i, name in enumerate(CATEGORY_MAPPING.keys()))}",
    "",
    "## Usage",
    "```python",
    "from segment_anything import sam_model_registry",
    "model = sam_model_registry['vit_b'](checkpoint='sam_hvac_final.pth')",
    "```",
    "",
    "## Performance",
    "- Optimized for Google Colab T4 GPU",
    "- Mixed precision training",
    "- Memory-efficient inference",
    "",
    "## Training Details",
    "- Dataset: HVAC blueprint annotations (COCO format)",
    "- Quality audit: Top 30% of images selected",
    "- Prompt engineering: Category-specific templates",
    "- Batch size: 1-2 (memory constraints)",
    "",
    "## Limitations",
    "- Optimized for technical drawings and blueprints",
    "- May require fine-tuning for other visual styles",
    "- Best performance on clear, high-resolution images",
    "",
    "\"\"\"",
    "    ",
    "    with open(\"MODEL_CARD.md\", \"w\") as f:",
    "        f.write(card)",
    "    ",
    "    print(\"\u2713 Model card created\")",
    "",
    "print(\"Export functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline Execution",
    "",
    "Run the complete pipeline end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline():",
    "    '''Execute the complete SAM HVAC pipeline'''",
    "    ",
    "    print(\"=\"*60)",
    "    print(\"SAM HVAC BLUEPRINT ANALYSIS PIPELINE\")",
    "    print(\"=\"*60)",
    "    ",
    "    # Phase 1: Setup (already done)",
    "    print(\"\\n[Phase 1] Environment Setup: \u2713\")",
    "    ",
    "    # Phase 2: Load dataset",
    "    print(\"\\n[Phase 2] Loading dataset...\")",
    "    try:",
    "        train_handler = COCOHandler(os.path.join(DATASET_ROOT, \"train\"))",
    "        valid_handler = COCOHandler(os.path.join(DATASET_ROOT, \"valid\"))",
    "        print(\"\u2713 Dataset loaded\")",
    "    except Exception as e:",
    "        print(f\"\u26a0\ufe0f Error loading dataset: {e}\")",
    "        print(\"Please ensure dataset is extracted to:\", DATASET_ROOT)",
    "        return",
    "    ",
    "    # Phase 3: Quality audit",
    "    print(\"\\n[Phase 3] Running quality audit...\")",
    "    auditor = QualityAuditor(train_handler)",
    "    auditor.audit_images(max_images=200)",
    "    selected_images = auditor.select_top_quality(percentile=30.0)",
    "    print(f\"\u2713 Selected {len(selected_images)} high-quality images\")",
    "    ",
    "    # Phase 4: Prompt engineering",
    "    print(\"\\n[Phase 4] Prompt engineering system: \u2713\")",
    "    ",
    "    # Phase 5: Prepare training",
    "    print(\"\\n[Phase 5] Preparing training...\")",
    "    train_dataset = HVACDataset(train_handler, selected_images)",
    "    train_loader = DataLoader(",
    "        train_dataset,",
    "        batch_size=config.batch_size,",
    "        shuffle=True,",
    "        num_workers=0  # Set to 0 for Colab",
    "    )",
    "    print(f\"\u2713 Training dataset ready: {len(train_dataset)} samples\")",
    "    ",
    "    # Initialize trainer",
    "    trainer = SAMFineTuner(config)",
    "    print(\"\u2713 Trainer initialized\")",
    "    ",
    "    # Start training (uncomment to run)",
    "    # print(\"\\nStarting training...\")",
    "    # trainer.train(train_loader, num_epochs=config.num_epochs)",
    "    ",
    "    # Phase 6: Inference",
    "    print(\"\\n[Phase 6] Inference pipeline: \u2713\")",
    "    ",
    "    # Phase 7: Export",
    "    print(\"\\n[Phase 7] Export and documentation...\")",
    "    create_model_card()",
    "    print(\"\u2713 Documentation created\")",
    "    ",
    "    print(\"\\n\" + \"=\"*60)",
    "    print(\"PIPELINE SETUP COMPLETE\")",
    "    print(\"=\"*60)",
    "    print(\"\\nTo start training, uncomment the training lines in run_complete_pipeline()\")",
    "",
    "# Execute if dataset is available",
    "if os.path.exists(DATASET_ROOT):",
    "    run_complete_pipeline()",
    "else:",
    "    print(\"\u26a0\ufe0f Dataset not found. Please upload and extract hvac-dataset.zip first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and Next Steps",
    "",
    "### Usage Instructions:",
    "1. Upload `hvac-dataset.zip` to Colab",
    "2. Extract to `/content/datasets`",
    "3. Run all cells in sequence",
    "4. Uncomment training lines to start training",
    "",
    "### Key Features:",
    "- \u2713 Complete dataset quality audit",
    "- \u2713 70+ to 6 class consolidation",
    "- \u2713 Comprehensive prompt engineering",
    "- \u2713 Memory-optimized training (T4 GPU)",
    "- \u2713 Mixed precision training",
    "- \u2713 Checkpoint saving",
    "- \u2713 Professional code structure",
    "",
    "### Customization:",
    "- Adjust `TrainingConfig` for different hyperparameters",
    "- Modify `CATEGORY_MAPPING` for different class groupings",
    "- Update quality thresholds in audit",
    "- Add custom prompt templates",
    "",
    "### Performance Tips:",
    "- Use gradient accumulation for larger effective batch sizes",
    "- Monitor GPU memory usage",
    "- Start with small subset for testing",
    "- Use mixed precision training",
    "",
    "### Troubleshooting:",
    "- If OOM errors: Reduce batch size or image size",
    "- If slow training: Check GPU utilization",
    "- If poor results: Audit more images or adjust quality thresholds",
    "",
    "**Author**: HVAC AI Development Team  ",
    "**License**: MIT  ",
    "**Version**: 1.0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}