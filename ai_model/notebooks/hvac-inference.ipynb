{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ HVAC AI - Remote Inference Server (v5 - Final)\n",
        "\n",
        "This notebook correctly launches the FastAPI backend from `hvac_analysis_service.py` using the standard `uvicorn` command."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 1: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Clone the GitHub repository\n",
        "!git clone https://github.com/elliotttmiller/hvac-ai.git\n",
        "\n",
        "# 2. Change the current working directory to the cloned repo\n",
        "%cd hvac-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Install all required Python packages\n",
        "!pip install fastapi uvicorn python-multipart --quiet\n",
        "!pip install flask flask-cors pyngrok python-dotenv --quiet\n",
        "!pip install torch torchvision --quiet\n",
        "!pip install opencv-python pycocotools matplotlib onnxruntime onnx --quiet\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git --quiet\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 2: Create and Configure `.env` File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile .env\n",
        "NGROK_AUTHTOKEN=\"YOUR_NGROK_AUTHTOKEN_HERE\"\n",
        "MODEL_PATH=\"/content/drive/MyDrive/sam_finetuning_results/best_model_expert_v1.pth\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 3: Authenticate `ngrok`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "ngrok_token = os.getenv(\"NGROK_AUTHTOKEN\")\n",
        "if ngrok_token and \"YOUR_NGROK_AUTHTOKEN_HERE\" not in ngrok_token:\n",
        "    !ngrok authtoken {ngrok_token}\n",
        "else:\n",
        "    print(\"‚ùå ERROR: NGROK_AUTHTOKEN not configured.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Phase 4: Launch the Inference Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pyngrok import ngrok\n",
        "import asyncio\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Drive mounted.\")\n",
        "\n",
        "# 2. Set up the ngrok tunnel\n",
        "PORT = 8000\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(PORT).public_url\n",
        "print(\"-\" * 50)\n",
        "print(f\"‚úÖ Your inference server is live at: {public_url}\")\n",
        "print(\"üëâ Use this URL in your frontend's .env.local file.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 3. Run the FastAPI Server using the correct uvicorn command\n",
        "# This runs the 'app' object inside the 'hvac_analysis_service.py' file.\n",
        "# The --host and --port flags tell uvicorn where to listen.\n",
        "# The --reload flag is helpful for development if you make changes to the .py file.\n",
        "print(\"\\nüöÄ Starting the FastAPI backend server with Uvicorn...\")\n",
        "!uvicorn python-services.hvac_analysis_service:app --host 0.0.0.0 --port 8000 --reload\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}