# .github/workflows/autodistill-gpu-pipeline.yml
name: HVAC-AI AutoDistill GPU Pipeline

on:
  workflow_dispatch: # Allow manual triggering
  push:
    branches: [main, dev]
    paths:
      - 'notebooks/**'
      - 'python-services/**'
      - '.github/workflows/autodistill-gpu-pipeline.yml'

jobs:
  run_autodistill_pipeline:
    # Use standard Ubuntu runner
    runs-on: ubuntu-latest
    # Request GPU hardware
    hardware:
      gpu: T4 # NVIDIA Tesla T4 GPU
    env:
      PYTHON_VERSION: "3.10"
      NOTEBOOK_FILE: "autodistill_pipeline.ipynb" # Update if your notebook name differs

    steps:
      # 1. Checkout code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Setup Python
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'python-services/requirements.txt'

      # 3. Install system dependencies
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            curl \
            wget \
            unzip \
            git \
            libgl1-mesa-glx \
            libglib2.0-0 \
            libsm6 \
            libxext6 \
            libxrender-dev \
            libgomp1 \
            ffmpeg

      # 4. Verify GPU availability
      - name: Verify GPU and CUDA
        run: |
          echo "=== GPU Check ==="
          if command -v nvidia-smi &> /dev/null; then
            echo "✅ nvidia-smi found"
            nvidia-smi
          else
            echo "❌ nvidia-smi NOT FOUND. GPU setup failed."
            exit 1
          fi

      # 5. Install Python dependencies
      - name: Install Python Dependencies
        run: |
          cd python-services
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install jupyter nbconvert
          # Check PyTorch and CUDA
          python -c "
          import torch;
          print(f'PyTorch: {torch.__version__}');
          print(f'CUDA available: {torch.cuda.is_available()}');
          if torch.cuda.is_available():
              print(f'CUDA version: {torch.version.cuda}');
              print(f'GPU count: {torch.cuda.device_count()}');
              print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else \"None\"}');
          "
          deactivate

      # 6. Execute notebook
      - name: Execute AutoDistill Notebook
        run: |
          cd python-services
          source venv/bin/activate
          cd ../notebooks
          if [ ! -f "${{ env.NOTEBOOK_FILE }}" ]; then
            echo "❌ Notebook ${{ env.NOTEBOOK_FILE }} not found in notebooks/"
            ls -la
            exit 1
          fi
          echo "Executing ${{ env.NOTEBOOK_FILE }}"
          jupyter nbconvert --execute --to notebook --output "executed_${{ env.NOTEBOOK_FILE }}" --ExecutePreprocessor.timeout=3600 "${{ env.NOTEBOOK_FILE }}"
          EXECUTION_EXIT_CODE=$?
          if [ $EXECUTION_EXIT_CODE -ne 0 ]; then
            echo "❌ Notebook execution failed with exit code $EXECUTION_EXIT_CODE"
            exit $EXECUTION_EXIT_CODE
          fi
          deactivate

      # 7. Upload results
      - name: Upload Executed Notebook
        uses: actions/upload-artifact@v4
        with:
          name: executed-notebook
          path: notebooks/executed_${{ env.NOTEBOOK_FILE }}
          retention-days: 7

  notify_completion:
    needs: run_autodistill_pipeline
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Report Status
        run: |
          STATUS="${{ needs.run_autodistill_pipeline.result }}"
          echo "Pipeline finished with status: $STATUS"
          if [ "$STATUS" = "success" ]; then
            echo "✅ Success!"
          else
            echo "❌ Failed. Check logs."
          fi