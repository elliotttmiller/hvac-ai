{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ HVAC AI ‚Äî YOLO11 Inference Server\n",
        "**Quick Start for YOLO11 Deployment**\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Simple 4-Step Deployment\n",
        "\n",
        "This is the **minimal** version for quick deployment. For production use with validation, monitoring, and testing, see:\n",
        "- `hvac-inference_yolo_enhanced.ipynb` - Full production-ready version\n",
        "\n",
        "### Prerequisites\n",
        "1. Set Colab runtime to **GPU** (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "2. Have your trained YOLO11 model (`.pt` file) in Google Drive\n",
        "3. Get ngrok token from [ngrok.com](https://ngrok.com/)\n",
        "\n",
        "### Steps\n",
        "1. **Setup** - Install dependencies\n",
        "2. **Mount Drive** - Access your model\n",
        "3. **Configure** - Set paths and tokens\n",
        "4. **Launch** - Start the API server\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup Environment\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "print(\"üì¶ Cloning repository...\")\n",
        "!git clone https://github.com/elliotttmiller/hvac-ai.git 2>/dev/null || echo \"Repository exists\"\n",
        "%cd hvac-ai\n",
        "\n",
        "print(\"\\nüìö Installing dependencies...\")\n",
        "!pip install -q ultralytics>=8.0.0 fastapi>=0.115.0 uvicorn[standard]>=0.34.0\n",
        "!pip install -q python-multipart>=0.0.9 pyngrok>=7.0.0 python-dotenv>=1.0.0\n",
        "\n",
        "print(\"\\nüîç Validating environment...\")\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! Set Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "\n",
        "print('\\n‚úÖ Environment Ready')"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Mount Drive (To access your best.pt)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "# 3. CONFIGURATION - UPDATE THESE VALUES\n",
        "# Get ngrok token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_AUTHTOKEN=\"YOUR_NGROK_TOKEN_HERE\"\n",
        "PORT=8000\n",
        "\n",
        "# Point this to your trained YOLO11 model in Google Drive\n",
        "# Example path format: /content/drive/MyDrive/your_project/weights/best.pt\n",
        "MODEL_PATH=\"/content/drive/MyDrive/hvac_detection_project/runs/segment/hvac_yolo11_segmentation_sota/weights/best.pt\"\n",
        "\n",
        "# Optional: Adjust inference settings\n",
        "# DEFAULT_CONF_THRESHOLD=0.50\n",
        "# DEFAULT_IOU_THRESHOLD=0.45"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Launch Server\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "print(\"üöÄ Launching API Server\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Validate configuration\n",
        "model_path = os.getenv('MODEL_PATH')\n",
        "ngrok_token = os.getenv('NGROK_AUTHTOKEN')\n",
        "\n",
        "if not model_path or not os.path.exists(model_path):\n",
        "    print(\"‚ùå ERROR: MODEL_PATH not found. Check your .env configuration above.\")\n",
        "    raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
        "\n",
        "print(f\"‚úÖ Model found: {model_path}\")\n",
        "\n",
        "# Setup ngrok tunnel\n",
        "if ngrok_token and ngrok_token != \"YOUR_NGROK_TOKEN_HERE\":\n",
        "    print(\"\\nüåê Setting up ngrok tunnel...\")\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(f\"\\n‚úÖ API LIVE!\")\n",
        "    print(f\"   Public URL: {public_url.public_url}\")\n",
        "    print(f\"   API Docs: {public_url.public_url}/docs\")\n",
        "    print(f\"   Health: {public_url.public_url}/health\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No ngrok token - server will be local only\")\n",
        "    print(\"   Local URL: http://localhost:8000\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üé¨ Starting server (Press STOP button to shutdown)...\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "%cd python-services\n",
        "!uvicorn hvac_analysis_service:app --host 0.0.0.0 --port 8000 --reload"
      ],
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}