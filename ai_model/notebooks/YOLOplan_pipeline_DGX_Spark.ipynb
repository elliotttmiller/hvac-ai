{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BDkYgRnBpTY"
      },
      "source": [
        "# \ud83d\ude80 NVIDIA DGX Spark Optimized HVAC Training Pipeline\n",
        "\n",
        "## YOLOplan + YOLO11 + Roboflow on DGX Infrastructure\n",
        "\n",
        "### \ud83c\udfaf Purpose\n",
        "This notebook is specifically optimized for **NVIDIA DGX Spark** infrastructure with multi-GPU support (A100/H100). It provides:\n",
        "- Optimal GPU utilization without overloading Spark resources\n",
        "- High-performance training with mixed precision and distributed support\n",
        "- Enterprise-grade model training for HVAC blueprint detection\n",
        "\n",
        "### \ud83d\udda5\ufe0f Hardware Requirements\n",
        "- **Platform**: NVIDIA DGX Station/Server with Spark\n",
        "- **GPU**: 1-8x NVIDIA A100 (40/80GB) or H100 (80GB)\n",
        "- **Memory**: 256GB+ system RAM recommended\n",
        "- **Storage**: High-speed NVMe for dataset storage\n",
        "\n",
        "### \u2699\ufe0f Optimizations\n",
        "- **Multi-GPU Support**: Efficient distribution across available GPUs\n",
        "- **Memory Management**: Controlled resource usage to prevent Spark overload\n",
        "- **Data Loading**: Optimized for NVMe storage with parallel workers\n",
        "- **Mixed Precision**: FP16 training for 2-3x speedup\n",
        "- **TensorRT Ready**: Models can be exported to TensorRT for inference\n",
        "\n",
        "### \ud83d\udccb Prerequisites\n",
        "```bash\n",
        "# Ensure CUDA toolkit is available\n",
        "nvidia-smi\n",
        "\n",
        "# Python environment with required packages\n",
        "pip install ultralytics roboflow pyyaml pandas matplotlib seaborn\n",
        "```\n",
        "\n",
        "### \ud83d\udd27 Configuration Notes\n",
        "- **Batch Size**: Automatically scaled based on available GPU memory\n",
        "- **Workers**: Set to CPU count / GPU count for optimal throughput\n",
        "- **Storage Paths**: Uses local NVMe paths (no cloud storage)\n",
        "- **Monitoring**: TensorBoard for real-time metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqshktTOCJyb"
      },
      "outputs": [],
      "source": [
        "# --- ENVIRONMENT VERIFICATION ---\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udda5\ufe0f  DGX SPARK ENVIRONMENT CHECK\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check CUDA availability\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    print(f\"\u2705 CUDA Available: {torch.version.cuda}\")\n",
        "    print(f\"\u2705 PyTorch Version: {torch.__version__}\")\n",
        "    print(f\"\u2705 GPU Count: {gpu_count}\")\n",
        "    print(\"\\n\ud83d\udcca GPU Details:\")\n",
        "    for i in range(gpu_count):\n",
        "        props = torch.cuda.get_device_properties(i)\n",
        "        print(f\"   GPU {i}: {props.name}\")\n",
        "        print(f\"      Memory: {props.total_memory / 1e9:.2f} GB\")\n",
        "        print(f\"      Compute Capability: {props.major}.{props.minor}\")\n",
        "else:\n",
        "    print(\"\u274c ERROR: No CUDA-capable GPU detected!\")\n",
        "    print(\"   This notebook requires NVIDIA GPU support.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Check cuDNN\n",
        "if torch.backends.cudnn.is_available():\n",
        "    print(f\"\\n\u2705 cuDNN Available: {torch.backends.cudnn.version()}\")\n",
        "    print(f\"   cuDNN Enabled: {torch.backends.cudnn.enabled}\")\n",
        "\n",
        "# System info\n",
        "print(\"\\n\ud83d\udcbb System Resources:\")\n",
        "try:\n",
        "    cpu_count = os.cpu_count()\n",
        "    print(f\"   CPU Cores: {cpu_count}\")\n",
        "    \n",
        "    # Get memory info on Linux\n",
        "    with open('/proc/meminfo', 'r') as f:\n",
        "        meminfo = f.read()\n",
        "        for line in meminfo.split('\\n'):\n",
        "            if 'MemTotal' in line:\n",
        "                mem_total = int(line.split()[1]) / 1e6\n",
        "                print(f\"   System RAM: {mem_total:.1f} GB\")\n",
        "                break\n",
        "except:\n",
        "    print(\"   (System info unavailable)\")\n",
        "\n",
        "# Check storage\n",
        "print(\"\\n\ud83d\udcbe Storage Check:\")\n",
        "workspace_dir = os.path.expanduser('~/hvac_workspace')\n",
        "if not os.path.exists(workspace_dir):\n",
        "    os.makedirs(workspace_dir, exist_ok=True)\n",
        "    print(f\"   Created workspace: {workspace_dir}\")\n",
        "else:\n",
        "    print(f\"   Workspace exists: {workspace_dir}\")\n",
        "\n",
        "# Set environment variables for optimal performance\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Async kernel launches\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'  # Device-side assertions\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 ENVIRONMENT CHECK COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n\ud83d\udcc1 Working Directory: {workspace_dir}\")\n",
        "print(\"\\n\ud83d\ude80 Ready to proceed with training!\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56yCxBxQBpTm"
      },
      "outputs": [],
      "source": [
        "# --- STEP 1: ENVIRONMENT SETUP FOR DGX ---\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udce6 INSTALLING DEPENDENCIES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Set workspace directory\n",
        "WORKSPACE_DIR = os.path.expanduser('~/hvac_workspace')\n",
        "os.makedirs(WORKSPACE_DIR, exist_ok=True)\n",
        "os.chdir(WORKSPACE_DIR)\n",
        "\n",
        "print(f\"\\n\ud83d\udcc1 Workspace: {WORKSPACE_DIR}\")\n",
        "\n",
        "# Install/upgrade required packages\n",
        "packages = [\n",
        "    'ultralytics',  # YOLO11\n",
        "    'roboflow',     # Dataset management\n",
        "    'pyyaml',       # Configuration\n",
        "    'pandas',       # Data analysis\n",
        "    'matplotlib',   # Plotting\n",
        "    'seaborn',      # Visualization\n",
        "    'tensorboard',  # Monitoring\n",
        "    'tqdm',         # Progress bars\n",
        "]\n",
        "\n",
        "print(\"\\n\ud83d\udd27 Installing/upgrading packages...\")\n",
        "for pkg in packages:\n",
        "    print(f\"   - {pkg}\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '--upgrade', pkg], \n",
        "                   check=False)\n",
        "\n",
        "print(\"\\n\u2705 Package installation complete\")\n",
        "\n",
        "# Clone YOLOplan repository if not exists\n",
        "yoloplan_dir = os.path.join(WORKSPACE_DIR, 'YOLOplan')\n",
        "if not os.path.exists(yoloplan_dir):\n",
        "    print(\"\\n\ud83d\udce5 Cloning YOLOplan repository...\")\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/cvicream/YOLOplan.git', yoloplan_dir],\n",
        "                   check=False, capture_output=True)\n",
        "    if os.path.exists(yoloplan_dir):\n",
        "        print(f\"   \u2705 Cloned to: {yoloplan_dir}\")\n",
        "    else:\n",
        "        print(\"   \u26a0\ufe0f YOLOplan clone skipped (may already exist or network issue)\")\n",
        "else:\n",
        "    print(f\"\\n\u2705 YOLOplan already exists: {yoloplan_dir}\")\n",
        "\n",
        "# Add YOLOplan to Python path\n",
        "if yoloplan_dir not in sys.path:\n",
        "    sys.path.insert(0, yoloplan_dir)\n",
        "\n",
        "# Verify installations\n",
        "print(\"\\n\ud83d\udd0d Verifying installations...\")\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import roboflow\n",
        "    import yaml\n",
        "    print(\"   \u2705 All required packages imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"   \u274c Import error: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 ENVIRONMENT SETUP COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n\ud83d\udcc2 Working in: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ERY4YERBpTw"
      },
      "outputs": [],
      "source": [
        "# --- STEP 2: SECURE DATA DOWNLOAD ---\n",
        "from roboflow import Roboflow\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udce5 ROBOFLOW DATASET DOWNLOAD\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get Roboflow credentials\n",
        "# Priority: 1) Environment variables, 2) User input\n",
        "RF_API_KEY = os.environ.get('ROBOFLOW_API_KEY')\n",
        "RF_WORKSPACE = os.environ.get('ROBOFLOW_WORKSPACE', 'hvac-detection')\n",
        "RF_PROJECT = os.environ.get('ROBOFLOW_PROJECT', 'hvac-blueprint-analysis')\n",
        "RF_VERSION = os.environ.get('ROBOFLOW_VERSION', '1')\n",
        "\n",
        "if not RF_API_KEY:\n",
        "    print(\"\u26a0\ufe0f ROBOFLOW_API_KEY not found in environment variables\")\n",
        "    print(\"\\nYou can set it in your environment:\")\n",
        "    print(\"   export ROBOFLOW_API_KEY='your-api-key'\")\n",
        "    print(\"\\nOr enter it now (input will be hidden):\")\n",
        "    RF_API_KEY = getpass.getpass(\"Roboflow API Key: \")\n",
        "\n",
        "if not RF_API_KEY:\n",
        "    print(\"\\n\u274c ERROR: Roboflow API key is required\")\n",
        "    raise ValueError(\"Missing Roboflow API key\")\n",
        "\n",
        "print(f\"\\n\ud83d\udd10 Using Roboflow credentials:\")\n",
        "print(f\"   Workspace: {RF_WORKSPACE}\")\n",
        "print(f\"   Project: {RF_PROJECT}\")\n",
        "print(f\"   Version: {RF_VERSION}\")\n",
        "\n",
        "# Set download location (local NVMe storage)\n",
        "DATASET_DIR = os.path.join(os.getcwd(), 'dataset')\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\\n\ud83d\udcc2 Download location: {DATASET_DIR}\")\n",
        "\n",
        "# Download dataset\n",
        "try:\n",
        "    print(\"\\n\u2b07\ufe0f Downloading dataset from Roboflow...\")\n",
        "    rf = Roboflow(api_key=RF_API_KEY)\n",
        "    project = rf.workspace(RF_WORKSPACE).project(RF_PROJECT)\n",
        "    dataset = project.version(RF_VERSION).download(\n",
        "        model_format=\"coco-segmentation\",\n",
        "        location=DATASET_DIR,\n",
        "        overwrite=False  # Skip if already downloaded\n",
        "    )\n",
        "    \n",
        "    DATASET_PATH = dataset.location\n",
        "    print(f\"\\n\u2705 Dataset downloaded successfully\")\n",
        "    print(f\"   Location: {DATASET_PATH}\")\n",
        "    \n",
        "    # Verify dataset structure\n",
        "    print(\"\\n\ud83d\udcca Dataset structure:\")\n",
        "    for split in ['train', 'valid', 'test']:\n",
        "        split_dir = os.path.join(DATASET_PATH, split)\n",
        "        if os.path.exists(split_dir):\n",
        "            img_count = len([f for f in os.listdir(split_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "            print(f\"   {split}: {img_count} images\")\n",
        "    \n",
        "    # Check for annotations\n",
        "    annotations_file = os.path.join(DATASET_PATH, 'train', '_annotations.coco.json')\n",
        "    if os.path.exists(annotations_file):\n",
        "        import json\n",
        "        with open(annotations_file, 'r') as f:\n",
        "            coco_data = json.load(f)\n",
        "        print(f\"\\n\ud83d\udcdd Annotations:\")\n",
        "        print(f\"   Images: {len(coco_data.get('images', []))}\")\n",
        "        print(f\"   Annotations: {len(coco_data.get('annotations', []))}\")\n",
        "        print(f\"   Categories: {len(coco_data.get('categories', []))}\")\n",
        "        \n",
        "        # List categories\n",
        "        if coco_data.get('categories'):\n",
        "            print(\"\\n\ud83c\udff7\ufe0f Classes:\")\n",
        "            for cat in coco_data['categories'][:10]:  # Show first 10\n",
        "                print(f\"      {cat['id']}: {cat['name']}\")\n",
        "            if len(coco_data['categories']) > 10:\n",
        "                print(f\"      ... and {len(coco_data['categories']) - 10} more\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n\u274c ERROR downloading dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 DATA DOWNLOAD COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Store for next cells\n",
        "globals()['DATASET_PATH'] = DATASET_PATH\n",
        "globals()['RF_VERSION'] = RF_VERSION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 2.5: AGGRESSIVE DATASET REPAIR & VALIDATION ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "DATASET_ROOT = \"/content/hvac_dataset\"\n",
        "SPLITS = ['train', 'valid', 'test']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"\ud83e\ude7a RUNNING AGGRESSIVE DATASET REPAIR & VALIDATION...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dataset_stats = {}\n",
        "\n",
        "for split in SPLITS:\n",
        "    split_path = os.path.join(DATASET_ROOT, split)\n",
        "    json_path = os.path.join(split_path, \"_annotations.coco.json\")\n",
        "    images_dir = os.path.join(split_path, \"images\")\n",
        "\n",
        "    if not os.path.isdir(split_path): \n",
        "        continue\n",
        "\n",
        "    print(f\"\\n--- Processing '{split}' split ---\")\n",
        "\n",
        "    # 1. ENFORCE FOLDER STRUCTURE\n",
        "    if not os.path.isdir(images_dir):\n",
        "        os.makedirs(images_dir, exist_ok=True)\n",
        "        image_files = glob.glob(os.path.join(split_path, '*.*'))\n",
        "        image_files = [f for f in image_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "        if image_files:\n",
        "            print(f\"   Moving {len(image_files)} images to '{images_dir}'...\")\n",
        "            for img in tqdm(image_files, leave=False):\n",
        "                try:\n",
        "                    shutil.move(img, images_dir)\n",
        "                except shutil.Error:\n",
        "                    pass\n",
        "\n",
        "    # 2. REPAIR JSON FILENAMES & COLLECT STATISTICS\n",
        "    if os.path.exists(json_path):\n",
        "        print(f\"   Repairing JSON metadata in: {os.path.basename(json_path)}\")\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            modified = False\n",
        "            valid_images = []\n",
        "            class_counts = defaultdict(int)\n",
        "            files_on_disk = set(os.listdir(images_dir))\n",
        "\n",
        "            for img_entry in data['images']:\n",
        "                original_name = img_entry['file_name']\n",
        "                clean_name = os.path.basename(original_name)\n",
        "\n",
        "                if original_name != clean_name:\n",
        "                    img_entry['file_name'] = clean_name\n",
        "                    modified = True\n",
        "\n",
        "                if clean_name in files_on_disk:\n",
        "                    valid_images.append(img_entry)\n",
        "\n",
        "            # Count annotations per class\n",
        "            for ann in data['annotations']:\n",
        "                cat_id = ann['category_id']\n",
        "                cat_name = next((c['name'] for c in data['categories'] if c['id'] == cat_id), 'unknown')\n",
        "                class_counts[cat_name] += 1\n",
        "\n",
        "            if len(valid_images) < len(data['images']):\n",
        "                print(f\"      \u26a0\ufe0f Removed {len(data['images']) - len(valid_images)} entries from JSON that had no matching image file.\")\n",
        "                data['images'] = valid_images\n",
        "                modified = True\n",
        "\n",
        "            if modified:\n",
        "                with open(json_path, 'w') as f:\n",
        "                    json.dump(data, f)\n",
        "                print(\"      \u2705 JSON fixed: Removed path prefixes and synced with disk.\")\n",
        "            else:\n",
        "                print(\"      \u2705 JSON was already correct.\")\n",
        "\n",
        "            # Store statistics\n",
        "            dataset_stats[split] = {\n",
        "                'num_images': len(valid_images),\n",
        "                'num_annotations': len(data['annotations']),\n",
        "                'num_classes': len(data['categories']),\n",
        "                'class_counts': dict(class_counts),\n",
        "                'categories': {c['id']: c['name'] for c in data['categories']}\n",
        "            }\n",
        "\n",
        "            print(f\"      \ud83d\udcca Statistics: {len(valid_images)} images, {len(data['annotations'])} annotations\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      \u274c Failed to parse JSON: {e}\")\n",
        "    else:\n",
        "        print(f\"      \u274c ERROR: Annotation file missing: {json_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\ud83c\udf89 REPAIR COMPLETE. Dataset ready for training.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 3. VISUALIZE DATASET STATISTICS\n",
        "if dataset_stats:\n",
        "    print(\"\\n\ud83d\udcca DATASET STATISTICS:\")\n",
        "    for split, stats in dataset_stats.items():\n",
        "        print(f\"\\n{split.upper()}:\")\n",
        "        print(f\"  Images: {stats['num_images']}\")\n",
        "        print(f\"  Annotations: {stats['num_annotations']}\")\n",
        "        print(f\"  Classes: {stats['num_classes']}\")\n",
        "        print(f\"  Avg annotations per image: {stats['num_annotations']/max(stats['num_images'],1):.2f}\")\n",
        "    \n",
        "    # Plot class distribution for training set\n",
        "    if 'train' in dataset_stats:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        class_counts = dataset_stats['train']['class_counts']\n",
        "        sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        classes, counts = zip(*sorted_classes)\n",
        "        \n",
        "        ax.bar(range(len(classes)), counts)\n",
        "        ax.set_xticks(range(len(classes)))\n",
        "        ax.set_xticklabels(classes, rotation=45, ha='right')\n",
        "        ax.set_xlabel('Class')\n",
        "        ax.set_ylabel('Number of Annotations')\n",
        "        ax.set_title('Training Set: Class Distribution')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Check for class imbalance\n",
        "        max_count = max(counts)\n",
        "        min_count = min(counts)\n",
        "        if max_count / min_count > 10:\n",
        "            print(f\"\\n\u26a0\ufe0f WARNING: Class imbalance detected! Ratio: {max_count/min_count:.1f}x\")\n",
        "            print(f\"   Consider using weighted loss or copy_paste augmentation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyZboXiBBpT0"
      },
      "outputs": [],
      "source": [
        "# --- STEP 3: CONVERT COCO TO YOLO TXT & GENERATE CONFIG ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import json\n",
        "import yaml\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "DATASET_ROOT = \"/content/hvac_dataset\"\n",
        "SPLITS = ['train', 'valid', 'test']\n",
        "OUTPUT_YAML_PATH = \"/content/hvac_config.yaml\"\n",
        "\n",
        "print(\"\u2699\ufe0f CONVERTING COCO JSON TO YOLO TXT FORMAT...\")\n",
        "\n",
        "def convert_coco_to_yolo(json_path, output_labels_dir):\n",
        "    \"\"\"Convert COCO format annotations to YOLO segmentation format.\"\"\"\n",
        "    if not os.path.exists(json_path): \n",
        "        return False\n",
        "\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    images = {img['id']: img for img in data['images']}\n",
        "    categories = {cat['id']: idx for idx, cat in enumerate(sorted(data['categories'], key=lambda x: x['id']))}\n",
        "\n",
        "    # Group annotations by image\n",
        "    img_annotations = {}\n",
        "    for ann in data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in img_annotations: \n",
        "            img_annotations[img_id] = []\n",
        "        img_annotations[img_id].append(ann)\n",
        "\n",
        "    # Write TXT files\n",
        "    os.makedirs(output_labels_dir, exist_ok=True)\n",
        "    count = 0\n",
        "\n",
        "    for img_id, anns in img_annotations.items():\n",
        "        img_info = images[img_id]\n",
        "        img_w, img_h = img_info['width'], img_info['height']\n",
        "        filename = os.path.basename(img_info['file_name'])\n",
        "        txt_name = os.path.splitext(filename)[0] + \".txt\"\n",
        "\n",
        "        with open(os.path.join(output_labels_dir, txt_name), 'w') as f:\n",
        "            for ann in anns:\n",
        "                cat_id = categories[ann['category_id']]\n",
        "\n",
        "                # Convert Polygon to Normalized Coordinates\n",
        "                # YOLO Seg format: <class> <x1> <y1> <x2> <y2> ...\n",
        "                segmentation = ann['segmentation'][0]\n",
        "                normalized_points = []\n",
        "                for i in range(0, len(segmentation), 2):\n",
        "                    x = segmentation[i] / img_w\n",
        "                    y = segmentation[i+1] / img_h\n",
        "                    normalized_points.append(f\"{x:.6f} {y:.6f}\")\n",
        "\n",
        "                f.write(f\"{cat_id} \" + \" \".join(normalized_points) + \"\\n\")\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "# 1. EXECUTE CONVERSION\n",
        "for split in SPLITS:\n",
        "    split_path = os.path.join(DATASET_ROOT, split)\n",
        "    json_path = os.path.join(split_path, \"_annotations.coco.json\")\n",
        "    labels_dir = os.path.join(split_path, \"labels\")\n",
        "    images_dir = os.path.join(split_path, \"images\")\n",
        "\n",
        "    # Move images if needed (Sanitization)\n",
        "    if not os.path.isdir(images_dir):\n",
        "        os.makedirs(images_dir, exist_ok=True)\n",
        "        files = glob.glob(os.path.join(split_path, '*.*'))\n",
        "        files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        for f in files: \n",
        "            shutil.move(f, images_dir)\n",
        "\n",
        "    # Convert Labels\n",
        "    if os.path.exists(json_path):\n",
        "        num_converted = convert_coco_to_yolo(json_path, labels_dir)\n",
        "        print(f\"   \u2705 Converted {num_converted} labels for '{split}'\")\n",
        "    else:\n",
        "        print(f\"   \u26a0\ufe0f No JSON found for '{split}'\")\n",
        "\n",
        "# 2. GENERATE CONFIG\n",
        "print(\"\u2699\ufe0f GENERATING LOCAL CONFIG...\")\n",
        "try:\n",
        "    # Get class names from train JSON\n",
        "    with open(os.path.join(DATASET_ROOT, \"train\", \"_annotations.coco.json\"), 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "    class_names = [cat['name'] for cat in sorted(coco_data['categories'], key=lambda x: x['id'])]\n",
        "\n",
        "    config = {\n",
        "        'path': DATASET_ROOT,\n",
        "        'train': \"train/images\",\n",
        "        'val': \"valid/images\",\n",
        "        'test': \"test/images\",\n",
        "        'nc': len(class_names),\n",
        "        'names': class_names\n",
        "    }\n",
        "    with open(OUTPUT_YAML_PATH, 'w') as f:\n",
        "        yaml.dump(config, f, sort_keys=False)\n",
        "    print(f\"\u2705 Config saved to: {OUTPUT_YAML_PATH}\")\n",
        "    print(f\"   Classes: {len(class_names)}\")\n",
        "    print(f\"   First 5 classes: {class_names[:5]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Config Generation Failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 3: DGX SPARK OPTIMIZED TRAINING CONFIGURATION ---\n",
        "import yaml\n",
        "import torch\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\u2699\ufe0f  CREATING DGX SPARK OPTIMIZED CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Detect GPU configuration\n",
        "gpu_count = torch.cuda.device_count()\n",
        "gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else 'unknown'\n",
        "gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9 if gpu_count > 0 else 0\n",
        "\n",
        "print(f\"\\n\ud83d\udda5\ufe0f Detected Hardware:\")\n",
        "print(f\"   GPUs: {gpu_count}x {gpu_name}\")\n",
        "print(f\"   Memory per GPU: {gpu_memory_gb:.1f} GB\")\n",
        "\n",
        "# Determine optimal settings based on GPU\n",
        "# These are conservative to avoid overloading Spark\n",
        "if 'A100' in gpu_name:\n",
        "    if gpu_memory_gb >= 80:\n",
        "        # A100 80GB\n",
        "        batch_per_gpu = 16\n",
        "        imgsz = 1280\n",
        "    else:\n",
        "        # A100 40GB\n",
        "        batch_per_gpu = 12\n",
        "        imgsz = 1024\n",
        "elif 'H100' in gpu_name:\n",
        "    # H100 80GB\n",
        "    batch_per_gpu = 20\n",
        "    imgsz = 1280\n",
        "elif 'V100' in gpu_name:\n",
        "    # V100 32GB\n",
        "    batch_per_gpu = 8\n",
        "    imgsz = 1024\n",
        "else:\n",
        "    # Conservative defaults\n",
        "    batch_per_gpu = 4\n",
        "    imgsz = 1024\n",
        "\n",
        "# Calculate total batch size (conservative for Spark)\n",
        "# Use max 4 GPUs to avoid overloading Spark cluster\n",
        "gpus_to_use = min(gpu_count, 4)\n",
        "total_batch = batch_per_gpu * gpus_to_use\n",
        "\n",
        "# Calculate optimal workers (conservative for Spark)\n",
        "cpu_count = os.cpu_count() or 8\n",
        "workers_per_gpu = max(2, min(4, cpu_count // gpus_to_use))\n",
        "total_workers = workers_per_gpu * gpus_to_use\n",
        "\n",
        "print(f\"\\n\ud83c\udfaf Optimized Settings:\")\n",
        "print(f\"   GPUs to use: {gpus_to_use} of {gpu_count} available\")\n",
        "print(f\"   Batch size: {batch_per_gpu} per GPU (total: {total_batch})\")\n",
        "print(f\"   Image size: {imgsz}\")\n",
        "print(f\"   Workers: {workers_per_gpu} per GPU (total: {total_workers})\")\n",
        "print(f\"   \u26a0\ufe0f Resource usage limited to avoid Spark overload\")\n",
        "\n",
        "# Set paths for DGX local storage\n",
        "workspace_dir = os.path.expanduser('~/hvac_workspace')\n",
        "data_yaml_path = os.path.join(workspace_dir, 'hvac_config.yaml')\n",
        "project_dir = os.path.join(workspace_dir, 'runs', 'segment')\n",
        "run_name = f'hvac_yolo11_dgx_{datetime.now().strftime(\"%Y%m%d_%H%M\")}'",
        "\n",
        "# Create comprehensive training configuration optimized for DGX Spark\n",
        "training_config = {\n",
        "    'metadata': {\n",
        "        'created_at': datetime.now().isoformat(),\n",
        "        'platform': 'NVIDIA DGX Spark',\n",
        "        'gpu_model': gpu_name,\n",
        "        'gpu_count': gpus_to_use,\n",
        "        'dataset_version': globals().get('RF_VERSION', '1'),\n",
        "        'description': 'DGX Spark optimized HVAC YOLO11 segmentation training'\n",
        "    },\n",
        "    \n",
        "    'paths': {\n",
        "        'data_yaml': data_yaml_path,\n",
        "        'project_dir': project_dir,\n",
        "        'run_name': run_name\n",
        "    },\n",
        "    \n",
        "    'model': {\n",
        "        'architecture': 'yolo11m-seg.pt',  # Medium model for balance\n",
        "        'pretrained': True,\n",
        "        'freeze_layers': None  # No freezing for full fine-tuning\n",
        "    },\n",
        "    \n",
        "    'hardware': {\n",
        "        'imgsz': imgsz,\n",
        "        'batch': total_batch,\n",
        "        'workers': total_workers,\n",
        "        'cache': False,  # Use disk to save RAM for Spark\n",
        "        'amp': True,     # Mixed precision (FP16) for 2-3x speedup\n",
        "        'device': list(range(gpus_to_use)),  # Use multiple GPUs\n",
        "        'cudnn_benchmark': True,  # Enable cuDNN autotuner\n",
        "    },\n",
        "    \n",
        "    'training': {\n",
        "        'epochs': 150,       # More epochs for DGX (faster training)\n",
        "        'patience': 30,      # Increased patience\n",
        "        'save_period': 10,   # Save checkpoints every 10 epochs\n",
        "        'close_mosaic': 20,  # Disable mosaic in last 20 epochs\n",
        "        'optimizer': 'AdamW',  # AdamW for better convergence\n",
        "        'lr0': 0.001,          # Initial learning rate\n",
        "        'lrf': 0.01,           # Final learning rate multiplier\n",
        "        'momentum': 0.937,\n",
        "        'weight_decay': 0.0005,\n",
        "        'warmup_epochs': 5.0,  # Longer warmup for stability\n",
        "        'warmup_momentum': 0.8,\n",
        "        'warmup_bias_lr': 0.1,\n",
        "        'cos_lr': True,        # Cosine learning rate schedule\n",
        "    },\n",
        "    \n",
        "    'augmentation': {\n",
        "        'augment': True,\n",
        "        \n",
        "        # Geometric augmentations (optimized for HVAC blueprints)\n",
        "        'mosaic': 1.0,        # Full mosaic for context\n",
        "        'mixup': 0.0,         # Disabled for technical drawings\n",
        "        'copy_paste': 0.4,    # Increased for small object density\n",
        "        'degrees': 15.0,      # Rotation for scan variations\n",
        "        'translate': 0.1,\n",
        "        'scale': 0.6,         # Scale variation\n",
        "        'shear': 0.0,         # No shear for technical drawings\n",
        "        'perspective': 0.0,   # No perspective warp\n",
        "        'fliplr': 0.5,        # Horizontal flip\n",
        "        'flipud': 0.5,        # Vertical flip\n",
        "        \n",
        "        # Color augmentations\n",
        "        'hsv_h': 0.015,       # Minimal hue variation\n",
        "        'hsv_s': 0.7,         # Saturation (faded ink simulation)\n",
        "        'hsv_v': 0.4,         # Brightness (dark scans)\n",
        "        \n",
        "        # Advanced augmentation\n",
        "        'use_albumentations': True,\n",
        "        'albumentations_p': 0.6,  # Higher probability on DGX\n",
        "    },\n",
        "    \n",
        "    'loss_weights': {\n",
        "        'box': 7.5,\n",
        "        'cls': 0.5,\n",
        "        'dfl': 1.5,\n",
        "        'seg': 1.0,  # Segmentation loss\n",
        "    },\n",
        "    \n",
        "    'validation': {\n",
        "        'val': True,\n",
        "        'plots': True,\n",
        "        'save_json': True,\n",
        "        'save_hybrid': True,\n",
        "        'conf': 0.001,        # Low confidence for validation\n",
        "        'iou': 0.6,\n",
        "        'max_det': 300,\n",
        "    },\n",
        "    \n",
        "    'logging': {\n",
        "        'verbose': True,\n",
        "        'tensorboard': True,\n",
        "        'exist_ok': True,\n",
        "    },\n",
        "    \n",
        "    'dgx_optimizations': {\n",
        "        'pin_memory': True,           # Pin memory for faster GPU transfer\n",
        "        'persistent_workers': True,   # Keep workers alive between epochs\n",
        "        'prefetch_factor': 2,         # Prefetch batches\n",
        "        'cuda_sync': False,           # Async CUDA operations\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "# Save configuration\n",
        "config_path = os.path.join(workspace_dir, 'training_config_dgx.yaml')\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(training_config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(f\"\\n\ud83d\udcbe Configuration saved to: {config_path}\")\n",
        "print(f\"\\n\ud83d\udcca Training Summary:\")\n",
        "print(f\"   Run name: {run_name}\")\n",
        "print(f\"   Epochs: {training_config['training']['epochs']}\")\n",
        "print(f\"   Learning rate: {training_config['training']['lr0']} \u2192 \"\n",
        "      f\"{training_config['training']['lr0'] * training_config['training']['lrf']}\")\n",
        "print(f\"   Optimizer: {training_config['training']['optimizer']}\")\n",
        "print(f\"   Warmup: {training_config['training']['warmup_epochs']} epochs\")\n",
        "\n",
        "print(\"\\n\ud83d\ude80 DGX Optimizations:\")\n",
        "print(f\"   \u2713 Multi-GPU support ({gpus_to_use} GPUs)\")\n",
        "print(f\"   \u2713 Mixed precision training (FP16)\")\n",
        "print(f\"   \u2713 cuDNN benchmark mode\")\n",
        "print(f\"   \u2713 Persistent workers\")\n",
        "print(f\"   \u2713 Pin memory\")\n",
        "print(f\"   \u2713 Prefetch factor: 2\")\n",
        "\n",
        "print(\"\\n\u26a0\ufe0f  Spark-Friendly Settings:\")\n",
        "print(f\"   \u2713 Limited to {gpus_to_use} GPUs (max 4)\")\n",
        "print(f\"   \u2713 Conservative batch size per GPU\")\n",
        "print(f\"   \u2713 Cache disabled (disk-based)\")\n",
        "print(f\"   \u2713 Worker count balanced with CPU cores\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 CONFIGURATION COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Store for next cells\n",
        "globals()['training_config'] = training_config\n",
        "globals()['config_path'] = config_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 4: DGX SPARK OPTIMIZED TRAINING EXECUTION ---\n",
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import gc\n",
        "\n",
        "# Load configuration\n",
        "workspace_dir = os.path.expanduser('~/hvac_workspace')\n",
        "config_path = os.path.join(workspace_dir, 'training_config_dgx.yaml')\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_DIR = config['paths']['project_dir']\n",
        "RUN_NAME = config['paths']['run_name']\n",
        "DATA_YAML = config['paths']['data_yaml']\n",
        "MODEL_ARCH = config['model']['architecture']\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\ude80 STARTING DGX SPARK OPTIMIZED TRAINING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project: {PROJECT_DIR}\")\n",
        "print(f\"Run: {RUN_NAME}\")\n",
        "print(f\"Data: {DATA_YAML}\")\n",
        "print(f\"Model: {MODEL_ARCH}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Display GPU status\n",
        "if torch.cuda.is_available():\n",
        "    gpu_count = torch.cuda.device_count()\n",
        "    print(f\"\\n\ud83d\udda5\ufe0f GPU Status:\")\n",
        "    for i in range(gpu_count):\n",
        "        props = torch.cuda.get_device_properties(i)\n",
        "        mem_allocated = torch.cuda.memory_allocated(i) / 1e9\n",
        "        mem_reserved = torch.cuda.memory_reserved(i) / 1e9\n",
        "        mem_total = props.total_memory / 1e9\n",
        "        print(f\"   GPU {i} ({props.name}):\")\n",
        "        print(f\"      Total: {mem_total:.2f} GB\")\n",
        "        print(f\"      Allocated: {mem_allocated:.2f} GB\")\n",
        "        print(f\"      Reserved: {mem_reserved:.2f} GB\")\n",
        "        print(f\"      Free: {mem_total - mem_reserved:.2f} GB\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f WARNING: No GPU detected!\")\n",
        "\n",
        "# Clear any cached memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"\\n\ud83e\uddf9 Cleared GPU cache\")\n",
        "\n",
        "# Enable cuDNN optimizations\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "print(\"\u2705 cuDNN benchmark mode enabled\")\n",
        "\n",
        "# Smart Resume Logic\n",
        "last_ckpt = os.path.join(PROJECT_DIR, RUN_NAME, \"weights\", \"last.pt\")\n",
        "resume_training = os.path.exists(last_ckpt)\n",
        "\n",
        "if resume_training:\n",
        "    print(f\"\\n\ud83d\udd04 RESUMING training from checkpoint: {last_ckpt}\")\n",
        "    print(\"   Loading model and optimizer state...\")\n",
        "    model = YOLO(last_ckpt)\n",
        "    \n",
        "    # Resume training\n",
        "    print(\"\\n\ud83c\udfc3 Resuming training...\\n\")\n",
        "    results = model.train(resume=True)\n",
        "    \n",
        "else:\n",
        "    print(f\"\\n\ud83c\udd95 STARTING NEW training run with {MODEL_ARCH}\")\n",
        "    print(\"   Initializing model...\")\n",
        "    model = YOLO(MODEL_ARCH)\n",
        "\n",
        "    # Prepare training arguments from config\n",
        "    device_list = config['hardware']['device']\n",
        "    if isinstance(device_list, list) and len(device_list) > 1:\n",
        "        # Multi-GPU training\n",
        "        device_str = ','.join(map(str, device_list))\n",
        "        print(f\"\\n\ud83d\udda5\ufe0f Multi-GPU training enabled: GPUs {device_str}\")\n",
        "    else:\n",
        "        device_str = str(device_list[0]) if isinstance(device_list, list) else str(device_list)\n",
        "        print(f\"\\n\ud83d\udda5\ufe0f Single-GPU training: GPU {device_str}\")\n",
        "    \n",
        "    train_args = {\n",
        "        # Paths\n",
        "        'data': DATA_YAML,\n",
        "        'project': PROJECT_DIR,\n",
        "        'name': RUN_NAME,\n",
        "        \n",
        "        # Hardware\n",
        "        'imgsz': config['hardware']['imgsz'],\n",
        "        'batch': config['hardware']['batch'],\n",
        "        'workers': config['hardware']['workers'],\n",
        "        'cache': config['hardware']['cache'],\n",
        "        'amp': config['hardware']['amp'],\n",
        "        'device': device_list,\n",
        "        \n",
        "        # Training\n",
        "        'epochs': config['training']['epochs'],\n",
        "        'patience': config['training']['patience'],\n",
        "        'save_period': config['training']['save_period'],\n",
        "        'close_mosaic': config['training']['close_mosaic'],\n",
        "        'optimizer': config['training']['optimizer'],\n",
        "        'lr0': config['training']['lr0'],\n",
        "        'lrf': config['training']['lrf'],\n",
        "        'momentum': config['training']['momentum'],\n",
        "        'weight_decay': config['training']['weight_decay'],\n",
        "        'warmup_epochs': config['training']['warmup_epochs'],\n",
        "        'warmup_momentum': config['training']['warmup_momentum'],\n",
        "        'warmup_bias_lr': config['training']['warmup_bias_lr'],\n",
        "        'cos_lr': config['training'].get('cos_lr', True),\n",
        "        \n",
        "        # Augmentation\n",
        "        'augment': config['augmentation']['augment'],\n",
        "        'mosaic': config['augmentation']['mosaic'],\n",
        "        'mixup': config['augmentation']['mixup'],\n",
        "        'copy_paste': config['augmentation']['copy_paste'],\n",
        "        'degrees': config['augmentation']['degrees'],\n",
        "        'translate': config['augmentation']['translate'],\n",
        "        'scale': config['augmentation']['scale'],\n",
        "        'shear': config['augmentation']['shear'],\n",
        "        'perspective': config['augmentation']['perspective'],\n",
        "        'fliplr': config['augmentation']['fliplr'],\n",
        "        'flipud': config['augmentation']['flipud'],\n",
        "        'hsv_h': config['augmentation']['hsv_h'],\n",
        "        'hsv_s': config['augmentation']['hsv_s'],\n",
        "        'hsv_v': config['augmentation']['hsv_v'],\n",
        "        \n",
        "        # Loss weights\n",
        "        'box': config['loss_weights']['box'],\n",
        "        'cls': config['loss_weights']['cls'],\n",
        "        'dfl': config['loss_weights']['dfl'],\n",
        "        'seg': config['loss_weights'].get('seg', 1.0),\n",
        "        \n",
        "        # Validation\n",
        "        'val': config['validation']['val'],\n",
        "        'plots': config['validation']['plots'],\n",
        "        'save_json': config['validation']['save_json'],\n",
        "        'save_hybrid': config['validation']['save_hybrid'],\n",
        "        'conf': config['validation']['conf'],\n",
        "        'iou': config['validation']['iou'],\n",
        "        'max_det': config['validation']['max_det'],\n",
        "        \n",
        "        # Logging\n",
        "        'verbose': config['logging']['verbose'],\n",
        "        'exist_ok': config['logging']['exist_ok'],\n",
        "    }\n",
        "    \n",
        "    print(\"\\n\ud83c\udfaf Training Configuration:\")\n",
        "    print(f\"   Epochs: {train_args['epochs']} (patience: {train_args['patience']})\")\n",
        "    print(f\"   Image Size: {train_args['imgsz']}\")\n",
        "    print(f\"   Batch Size: {train_args['batch']} (total across GPUs)\")\n",
        "    print(f\"   Workers: {train_args['workers']}\")\n",
        "    print(f\"   Learning Rate: {train_args['lr0']} \u2192 {train_args['lr0'] * train_args['lrf']}\")\n",
        "    print(f\"   Optimizer: {train_args['optimizer']} (cosine schedule: {train_args['cos_lr']})\")\n",
        "    print(f\"   Mixed Precision: {train_args['amp']}\")\n",
        "    print(f\"   Augmentations: Mosaic={train_args['mosaic']}, CopyPaste={train_args['copy_paste']}\")\n",
        "    \n",
        "    print(\"\\n\u26a1 DGX Performance Features:\")\n",
        "    print(f\"   \u2713 Multi-GPU: {len(device_list) if isinstance(device_list, list) else 1} GPUs\")\n",
        "    print(f\"   \u2713 Mixed Precision (FP16): 2-3x speedup\")\n",
        "    print(f\"   \u2713 cuDNN Benchmark: Auto-optimized kernels\")\n",
        "    print(f\"   \u2713 High-speed NVMe data loading\")\n",
        "    \n",
        "    print(\"\\n\ud83c\udfc3 Starting training...\")\n",
        "    print(\"   Monitor progress in TensorBoard (next cell)\")\n",
        "    print(\"   Training may take several hours depending on dataset size\")\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "    \n",
        "    # Start training\n",
        "    try:\n",
        "        results = model.train(**train_args)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"\u2705 TRAINING COMPLETE\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Best model: {os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'best.pt')}\")\n",
        "        print(f\"Last checkpoint: {os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'last.pt')}\")\n",
        "        \n",
        "        # Display final metrics\n",
        "        if hasattr(results, 'results_dict'):\n",
        "            metrics = results.results_dict\n",
        "            print(\"\\n\ud83d\udcca Final Metrics:\")\n",
        "            if 'metrics/mAP50(B)' in metrics:\n",
        "                print(f\"   Box mAP50: {metrics['metrics/mAP50(B)']:.4f}\")\n",
        "            if 'metrics/mAP50-95(B)' in metrics:\n",
        "                print(f\"   Box mAP50-95: {metrics['metrics/mAP50-95(B)']:.4f}\")\n",
        "            if 'metrics/mAP50(M)' in metrics:\n",
        "                print(f\"   Mask mAP50: {metrics['metrics/mAP50(M)']:.4f}\")\n",
        "            if 'metrics/mAP50-95(M)' in metrics:\n",
        "                print(f\"   Mask mAP50-95: {metrics['metrics/mAP50-95(M)']:.4f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u274c ERROR during training: {e}\")\n",
        "        print(\"\\n\ud83d\udca1 Troubleshooting tips:\")\n",
        "        print(\"   - Check GPU memory: reduce batch size if OOM\")\n",
        "        print(\"   - Verify data.yaml path is correct\")\n",
        "        print(\"   - Ensure dataset has train/val splits\")\n",
        "        print(\"   - Check TensorBoard logs for details\")\n",
        "        raise\n",
        "    \n",
        "    finally:\n",
        "        # Clean up GPU memory\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            print(\"\\n\ud83e\uddf9 GPU memory cleared\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\ud83c\udf89 TRAINING SESSION COMPLETE\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 5: TENSORBOARD MONITORING ---\n",
        "import os\n",
        "import yaml\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Load configuration\n",
        "workspace_dir = os.path.expanduser('~/hvac_workspace')\n",
        "config_path = os.path.join(workspace_dir, 'training_config_dgx.yaml')\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "runs_dir = config['paths']['project_dir']\n",
        "run_name = config['paths']['run_name']\n",
        "tensorboard_dir = os.path.join(runs_dir, run_name)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udcca TENSORBOARD MONITORING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nLog directory: {tensorboard_dir}\")\n",
        "print(\"\\n\ud83d\ude80 Launch TensorBoard with:\")\n",
        "print(f\"\\n   tensorboard --logdir {tensorboard_dir} --port 6006\")\n",
        "print(\"\\n\ud83d\udcca Metrics to monitor:\")\n",
        "print(\"   - Loss curves (train/val)\")\n",
        "print(\"   - mAP50 and mAP50-95\")\n",
        "print(\"   - Precision and Recall\")\n",
        "print(\"   - Learning rate schedule\")\n",
        "print(\"   - GPU utilization\")\n",
        "print(\"\\n\ud83d\udca1 Access TensorBoard:\")\n",
        "print(\"   1. Open a terminal on DGX\")\n",
        "print(f\"   2. Run: tensorboard --logdir {tensorboard_dir} --port 6006\")\n",
        "print(\"   3. Navigate to: http://localhost:6006\")\n",
        "print(\"   4. Or tunnel via SSH: ssh -L 6006:localhost:6006 dgx-server\")\n",
        "\n",
        "# Try to load TensorBoard in notebook if possible\n",
        "try:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir {tensorboard_dir} --port 6006\n",
        "except:\n",
        "    print(\"\\n\u26a0\ufe0f TensorBoard extension not available in this environment\")\n",
        "    print(\"   Use the command-line instructions above instead.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 6: MODEL EVALUATION & COMPARISON ---\n",
        "import os\n",
        "import yaml\n",
        "import json\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load configuration\n",
        "with open('os.path.join(os.path.expanduser('~/hvac_workspace'), 'training_config_dgx.yaml')', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_DIR = config['paths']['project_dir']\n",
        "RUN_NAME = config['paths']['run_name']\n",
        "best_model_path = os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'best.pt')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udcca MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"Loading best model from: {best_model_path}\")\n",
        "    model = YOLO(best_model_path)\n",
        "    \n",
        "    # Run validation\n",
        "    print(\"\\n\ud83d\udd0d Running validation on test set...\")\n",
        "    results = model.val(\n",
        "        data=config['paths']['data_yaml'],\n",
        "        split='test',\n",
        "        imgsz=config['hardware']['imgsz'],\n",
        "        batch=config['hardware']['batch'],\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        plots=True,\n",
        "        save_json=True\n",
        "    )\n",
        "    \n",
        "    # Display results\n",
        "    print(\"\\n\ud83d\udcc8 Validation Results:\")\n",
        "    print(f\"   mAP50: {results.box.map50:.4f}\")\n",
        "    print(f\"   mAP50-95: {results.box.map:.4f}\")\n",
        "    print(f\"   Precision: {results.box.mp:.4f}\")\n",
        "    print(f\"   Recall: {results.box.mr:.4f}\")\n",
        "    \n",
        "    if hasattr(results, 'seg'):\n",
        "        print(f\"\\n   Mask mAP50: {results.seg.map50:.4f}\")\n",
        "        print(f\"   Mask mAP50-95: {results.seg.map:.4f}\")\n",
        "    \n",
        "    # Per-class results\n",
        "    print(\"\\n\ud83d\udcca Per-Class Performance:\")\n",
        "    class_results = []\n",
        "    for i, (name, map50, map) in enumerate(zip(model.names.values(), results.box.map50_per_class, results.box.map_per_class)):\n",
        "        class_results.append({\n",
        "            'Class': name,\n",
        "            'mAP50': float(map50),\n",
        "            'mAP50-95': float(map)\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(class_results)\n",
        "    df = df.sort_values('mAP50-95', ascending=False)\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    # Save results\n",
        "    results_path = os.path.join(PROJECT_DIR, RUN_NAME, 'evaluation_results.json')\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump({\n",
        "            'overall': {\n",
        "                'mAP50': float(results.box.map50),\n",
        "                'mAP50-95': float(results.box.map),\n",
        "                'precision': float(results.box.mp),\n",
        "                'recall': float(results.box.mr)\n",
        "            },\n",
        "            'per_class': class_results\n",
        "        }, f, indent=2)\n",
        "    print(f\"\\n\ud83d\udcbe Results saved to: {results_path}\")\n",
        "    \n",
        "    # Visualize per-class performance\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # mAP50 bar plot\n",
        "    axes[0].barh(df['Class'][:10], df['mAP50'][:10])\n",
        "    axes[0].set_xlabel('mAP50')\n",
        "    axes[0].set_title('Top 10 Classes by mAP50')\n",
        "    axes[0].set_xlim([0, 1])\n",
        "    \n",
        "    # mAP50-95 bar plot\n",
        "    axes[1].barh(df['Class'][:10], df['mAP50-95'][:10])\n",
        "    axes[1].set_xlabel('mAP50-95')\n",
        "    axes[1].set_title('Top 10 Classes by mAP50-95')\n",
        "    axes[1].set_xlim([0, 1])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(PROJECT_DIR, RUN_NAME, 'class_performance.png'))\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(f\"\u274c Model not found: {best_model_path}\")\n",
        "    print(\"   Please ensure training completed successfully.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 EVALUATION COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 7: EXPORT MODEL FOR DEPLOYMENT ---\n",
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load configuration\n",
        "with open('os.path.join(os.path.expanduser('~/hvac_workspace'), 'training_config_dgx.yaml')', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_DIR = config['paths']['project_dir']\n",
        "RUN_NAME = config['paths']['run_name']\n",
        "best_model_path = os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'best.pt')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\ud83d\udce6 MODEL EXPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model = YOLO(best_model_path)\n",
        "    \n",
        "    # Export to ONNX for production deployment\n",
        "    print(\"\\n\ud83d\udd04 Exporting to ONNX format...\")\n",
        "    onnx_path = model.export(\n",
        "        format='onnx',\n",
        "        imgsz=config['hardware']['imgsz'],\n",
        "        optimize=True,\n",
        "        simplify=True\n",
        "    )\n",
        "    print(f\"\u2705 ONNX model saved to: {onnx_path}\")\n",
        "    \n",
        "    # Optional: Export to TorchScript\n",
        "    print(\"\\n\ud83d\udd04 Exporting to TorchScript format...\")\n",
        "    torchscript_path = model.export(\n",
        "        format='torchscript',\n",
        "        imgsz=config['hardware']['imgsz']\n",
        "    )\n",
        "    print(f\"\u2705 TorchScript model saved to: {torchscript_path}\")\n",
        "    \n",
        "    # Model info\n",
        "    print(\"\\n\ud83d\udcca Model Information:\")\n",
        "    print(f\"   Architecture: {config['model']['architecture']}\")\n",
        "    print(f\"   Input Size: {config['hardware']['imgsz']}\")\n",
        "    print(f\"   Classes: {len(model.names)}\")\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.model.parameters())/1e6:.2f}M\")\n",
        "    \n",
        "    print(\"\\n\ud83d\ude80 Deployment Instructions:\")\n",
        "    print(\"   1. Copy the exported model to your deployment environment\")\n",
        "    print(\"   2. Use ONNX Runtime for efficient inference\")\n",
        "    print(\"   3. Recommended confidence threshold: 0.25\")\n",
        "    print(\"   4. Recommended IoU threshold: 0.45\")\n",
        "    \n",
        "else:\n",
        "    print(f\"\u274c Model not found: {best_model_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\u2705 EXPORT COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udf89 DGX Spark Training Complete!\n",
        "\n",
        "### \u2705 What Was Accomplished\n",
        "- \u2713 Trained YOLO11 model on NVIDIA DGX infrastructure\n",
        "- \u2713 Utilized multi-GPU acceleration (if available)\n",
        "- \u2713 Optimized for Spark resource management\n",
        "- \u2713 Generated production-ready model exports\n",
        "\n",
        "### \ud83d\udcca Next Steps\n",
        "\n",
        "#### 1. Review Results\n",
        "- Check TensorBoard logs: `tensorboard --logdir ~/hvac_workspace/runs/segment/[run_name]`\n",
        "- Review evaluation metrics in the cells above\n",
        "- Examine per-class performance for problem areas\n",
        "\n",
        "#### 2. Test Inference\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Load best model\n",
        "model_path = os.path.expanduser('~/hvac_workspace/runs/segment/[run_name]/weights/best.pt')\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Run inference\n",
        "results = model.predict(\n",
        "    source='path/to/test/images',\n",
        "    save=True,\n",
        "    conf=0.25,\n",
        "    iou=0.45\n",
        ")\n",
        "```\n",
        "\n",
        "#### 3. Optimize Further\n",
        "If results need improvement:\n",
        "- **Low mAP**: Increase epochs, collect more data, or adjust augmentation\n",
        "- **Overfitting**: Increase augmentation strength, add more regularization\n",
        "- **Class imbalance**: Use copy_paste augmentation, weighted sampling\n",
        "- **Small objects**: Increase image size to 1280 or 1536\n",
        "\n",
        "#### 4. Deploy to Production\n",
        "\n",
        "**Option A: ONNX Deployment (Recommended)**\n",
        "```bash\n",
        "# Model is already exported to ONNX format\n",
        "# Use ONNX Runtime for inference\n",
        "pip install onnxruntime-gpu\n",
        "```\n",
        "\n",
        "**Option B: TensorRT (Maximum Performance)**\n",
        "```python\n",
        "# Export to TensorRT on DGX\n",
        "model.export(format='engine', device=0, half=True, imgsz=1024)\n",
        "```\n",
        "\n",
        "**Option C: Native PyTorch**\n",
        "```python\n",
        "# Use best.pt directly with Ultralytics\n",
        "model = YOLO('best.pt')\n",
        "```\n",
        "\n",
        "### \ud83d\udd27 DGX Spark Best Practices\n",
        "\n",
        "#### Resource Management\n",
        "- **Monitor GPU usage**: `nvidia-smi -l 1` to watch in real-time\n",
        "- **Check Spark resources**: Ensure you're not overloading the cluster\n",
        "- **Batch size tuning**: Adjust based on GPU memory and throughput\n",
        "- **Worker count**: Balance between CPU cores and I/O bandwidth\n",
        "\n",
        "#### Multi-GPU Training\n",
        "For even faster training, you can use more GPUs:\n",
        "```python\n",
        "# Edit training_config_dgx.yaml\n",
        "# hardware:\n",
        "#   device: [0, 1, 2, 3]  # Use 4 GPUs\n",
        "#   batch: 48  # 12 per GPU\n",
        "```\n",
        "\n",
        "#### Storage Considerations\n",
        "- Use NVMe storage for datasets (faster I/O)\n",
        "- Keep models and checkpoints on high-speed storage\n",
        "- Archive old runs to slower storage\n",
        "\n",
        "### \ud83d\udc1b Troubleshooting\n",
        "\n",
        "#### Out of Memory (OOM)\n",
        "```python\n",
        "# Reduce batch size\n",
        "batch: 8  # instead of 12\n",
        "\n",
        "# Or reduce image size\n",
        "imgsz: 640  # instead of 1024\n",
        "```\n",
        "\n",
        "#### Slow Training\n",
        "- Enable AMP (mixed precision): `amp: True`\n",
        "- Increase workers: `workers: 16`\n",
        "- Use `cache: True` if you have enough RAM\n",
        "- Enable cuDNN benchmark: Already enabled in this notebook\n",
        "\n",
        "#### Spark Resource Conflicts\n",
        "- Limit GPU usage: `device: [0, 1]` instead of all GPUs\n",
        "- Reduce worker count to free CPU cores\n",
        "- Check with your cluster admin for resource allocation\n",
        "\n",
        "### \ud83d\udcda Additional Resources\n",
        "- [Ultralytics YOLO Documentation](https://docs.ultralytics.com/)\n",
        "- [NVIDIA DGX Best Practices](https://docs.nvidia.com/dgx/)\n",
        "- [TensorRT Optimization Guide](https://docs.nvidia.com/deeplearning/tensorrt/)\n",
        "- Project repository: Check `ai_model/OPTIMIZATION_GUIDE.md`\n",
        "\n",
        "### \ud83d\udd12 Security Notes\n",
        "- Store API keys in environment variables, not in code\n",
        "- Use `.gitignore` to exclude model weights from version control\n",
        "- Keep dataset access controls in place\n",
        "- Review model outputs before deploying to production\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Training! \ud83d\ude80**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}