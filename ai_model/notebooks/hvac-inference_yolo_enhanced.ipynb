{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fXLkcSp5Ljj"
      },
      "source": [
        "# üöÄ HVAC AI ‚Äî Production-Ready YOLO11 Inference Server\n",
        "**Optimized Turn-Key Backend/Inference Notebook**\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Overview\n",
        "Production-ready YOLO11 inference deployment with:\n",
        "- ‚úÖ Comprehensive GPU & dependency validation\n",
        "- ‚úÖ Optimized configuration management\n",
        "- ‚úÖ Error handling & monitoring\n",
        "- ‚úÖ Testing & benchmarking\n",
        "- ‚úÖ Security best practices\n",
        "- ‚úÖ Turn-key deployment\n",
        "\n",
        "## üéØ Prerequisites\n",
        "1. **GPU Runtime**: T4 or better (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "2. **Trained Model**: YOLO11 `.pt` file in Google Drive\n",
        "3. **Ngrok Token**: Free token from [ngrok.com](https://ngrok.com/)\n",
        "4. **Test Image**: Sample HVAC blueprint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMM7FrIo5P26",
        "outputId": "2f88769a-e851-4914-864f-092991c1c5b0"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive for model access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Drive mounted at: /content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RUwtJpK5Ljn",
        "outputId": "279612ad-1e44-4a9f-b31d-ad5b325bb190"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîß Environment Setup & Validation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Clone repository\n",
        "print(\"\\nüì¶ Cloning repository...\")\n",
        "!git clone https://github.com/elliotttmiller/hvac-ai.git 2>/dev/null || echo \"Repository exists\"\n",
        "%cd hvac-ai\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\nüìö Installing dependencies (2-3 minutes)...\")\n",
        "!pip install -q ultralytics>=8.0.0 fastapi>=0.115.0 uvicorn[standard]>=0.34.0\n",
        "!pip install -q python-multipart>=0.0.9 pyngrok>=7.0.0 python-dotenv>=1.0.0\n",
        "!pip install -q Pillow>=10.0.0 numpy>=1.24.0 tqdm>=4.65.0\n",
        "\n",
        "# Validate environment\n",
        "print(\"\\nüîç System Validation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import torch\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "print(f\"üî• PyTorch: {torch.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\n‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"   CUDA: {torch.version.cuda}\")\n",
        "    # Test GPU\n",
        "    test_tensor = torch.rand(1000, 1000).cuda()\n",
        "    _ = torch.matmul(test_tensor, test_tensor)\n",
        "    print(f\"   Test: ‚úÖ PASSED\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: No GPU! Set Runtime > GPU. Inference will be SLOW.\")\n",
        "\n",
        "print(\"\\n‚úÖ Environment Ready!\")\n",
        "print('=' * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax3wqr4_5Ljr",
        "outputId": "89da66aa-5444-43e1-c378-6b03ecf477ea"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"‚öôÔ∏è  Configuration\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# --- UPDATE THESE VALUES ---\n",
        "MODEL_PATH = \"/content/drive/Shareddrives/HVAC/DECEMBER 24 OUTPUT WEIGHTS {dataset2}/hvac_obb_l_20251224_223009/weights/best.pt\"\n",
        "NGROK_AUTHTOKEN = \"36hBoLt4A3L8yOYt96wKiCxxrwp_5wFbj1Frv6GoHARRQ6H6t\"  # Get from ngrok.com\n",
        "\n",
        "# Server settings\n",
        "PORT = 8000\n",
        "DEFAULT_CONF_THRESHOLD = 0.50\n",
        "DEFAULT_IOU_THRESHOLD = 0.45\n",
        "MAX_IMAGE_SIZE = 1024\n",
        "\n",
        "# Validation\n",
        "errors = []\n",
        "if not MODEL_PATH or not os.path.exists(MODEL_PATH):\n",
        "    errors.append(\"‚ùå MODEL_PATH invalid or not found\")\n",
        "else:\n",
        "    print(f\"‚úÖ Model: {MODEL_PATH}\")\n",
        "    print(f\"   Size: {os.path.getsize(MODEL_PATH) / 1e6:.1f} MB\")\n",
        "\n",
        "if not NGROK_AUTHTOKEN or NGROK_AUTHTOKEN == \"YOUR_NGROK_TOKEN_HERE\":\n",
        "    print(\"‚ö†Ô∏è  Ngrok token not set (optional, for public URL)\")\n",
        "else:\n",
        "    print(f\"‚úÖ Ngrok: {'*' * 20}{NGROK_AUTHTOKEN[-8:]}\")\n",
        "\n",
        "print(f\"\\nüéØ Inference: conf={DEFAULT_CONF_THRESHOLD}, iou={DEFAULT_IOU_THRESHOLD}, size={MAX_IMAGE_SIZE}\")\n",
        "\n",
        "# Write .env\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"MODEL_PATH={MODEL_PATH}\\nNGROK_AUTHTOKEN={NGROK_AUTHTOKEN}\\nPORT={PORT}\\n\")\n",
        "\n",
        "if errors:\n",
        "    print(\"\\n‚ùå Errors:\", \"\\n\".join(errors))\n",
        "else:\n",
        "    print(\"\\n‚úÖ Configuration valid\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_gsoC_f5Ljs",
        "outputId": "5b327d76-8786-4276-e9df-dcb8e8a7629d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"ü§ñ Model Loading & Validation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nüì• Loading model (10-30s)...\")\n",
        "start = time.time()\n",
        "model = YOLO(MODEL_PATH)\n",
        "print(f\"‚úÖ Loaded in {time.time() - start:.2f}s\")\n",
        "\n",
        "print(f\"\\nüìä Model Info:\")\n",
        "print(f\"   Device: {model.device}\")\n",
        "print(f\"   Classes: {len(model.names)}\")\n",
        "for idx, name in model.names.items():\n",
        "    print(f\"   [{idx}] {name}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.to('cuda')\n",
        "    print(f\"\\nüöÄ Model on GPU\")\n",
        "\n",
        "# Warm-up\n",
        "print(f\"\\nüî• Warm-up inference...\")\n",
        "dummy = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)\n",
        "start = time.time()\n",
        "_ = model.predict(dummy, verbose=False, conf=0.25)\n",
        "first_time = time.time() - start\n",
        "start = time.time()\n",
        "_ = model.predict(dummy, verbose=False, conf=0.25)\n",
        "second_time = time.time() - start\n",
        "\n",
        "print(f\"   First: {first_time*1000:.1f}ms\")\n",
        "print(f\"   Subsequent: {second_time*1000:.1f}ms (~{1.0/second_time:.0f} FPS)\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\nüíæ GPU Memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "\n",
        "print(\"\\n‚úÖ Model ready!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eRMzH1w45Ljt",
        "outputId": "1dcefc17-5f66-4d83-9719-fcac2d604472"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "print(\"üöÄ HVAC AI ‚Äî Corrected Pipeline for OBB Model\")\n",
        "print(\"=\"*70)\n",
        "print(\"‚úÖ Features: Binary image input | OBB-specific handling | No destructive corrections\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# =====================================================================\n",
        "# MODEL LOADING (OBB-SPECIFIC)\n",
        "# =====================================================================\n",
        "print(\"\\nüîß Model Loading - OBB Specific Configuration\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "MODEL_PATH = \"/content/drive/Shareddrives/HVAC/DECEMBER 24 OUTPUT WEIGHTS {dataset2}/hvac_obb_l_20251224_223009/weights/best.pt\"\n",
        "DEFAULT_CONF_THRESHOLD = 0.50  # Match your original working threshold\n",
        "DEFAULT_IOU_THRESHOLD = 0.45\n",
        "MAX_IMAGE_SIZE = 1024\n",
        "\n",
        "# Verify model path\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"‚ùå ERROR: Model not found at {MODEL_PATH}\")\n",
        "    print(\"   Please check your model path\")\n",
        "    raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Model found: {os.path.getsize(MODEL_PATH) / 1e6:.1f} MB\")\n",
        "\n",
        "# Load model\n",
        "try:\n",
        "    print(\"üì• Loading OBB model...\")\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    print(\"‚úÖ Model loaded successfully\")\n",
        "\n",
        "    # Verify it's an OBB model\n",
        "    is_obb = hasattr(model, 'predict_obb') or 'obb' in MODEL_PATH.lower()\n",
        "    print(f\"üîç Model Type: {'OBB' if is_obb else 'Standard'}\")\n",
        "\n",
        "    if not is_obb:\n",
        "        print(\"‚ö†Ô∏è Warning: This doesn't appear to be an OBB model\")\n",
        "\n",
        "    # GPU setup\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda')\n",
        "        print(\"üöÄ Model moved to GPU\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading model: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# =====================================================================\n",
        "# IMAGE UPLOAD & PREPROCESSING (BINARY PRESERVATION)\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üñºÔ∏è Image Upload & Binary Preservation\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nüì§ Upload test image...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"‚ùå No image uploaded. Please upload an image to continue.\")\n",
        "    raise ValueError(\"No image uploaded\")\n",
        "\n",
        "img_path = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Image uploaded: {img_path}\")\n",
        "\n",
        "try:\n",
        "    # Open as grayscale first (critical for binary preservation)\n",
        "    img = Image.open(img_path).convert('L')  # 'L' = 8-bit pixels, black and white\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    print(f\"\\nüìä Image Analysis:\")\n",
        "    print(f\"   Dimensions: {img.size[0]}x{img.size[1]} pixels\")\n",
        "    print(f\"   Mode: {img.mode} (grayscale for binary processing)\")\n",
        "\n",
        "    # Preserve binary nature - no contrast/brightness adjustments\n",
        "    print(\"\\nüîç Binary Image Preservation:\")\n",
        "    print(\"   ‚Ä¢ Keeping original contrast levels\")\n",
        "    print(\"   ‚Ä¢ No color correction applied\")\n",
        "    print(\"   ‚Ä¢ Preserving black/white characteristics\")\n",
        "\n",
        "    # Convert to binary (0 and 255 only)\n",
        "    _, binary_img = cv2.threshold(img_array, 128, 255, cv2.THRESH_BINARY)\n",
        "    binary_pil = Image.fromarray(binary_img)\n",
        "\n",
        "    # Convert to RGB for YOLO (but maintain binary characteristics)\n",
        "    rgb_img = binary_pil.convert('RGB')\n",
        "    img_array = np.array(rgb_img)\n",
        "\n",
        "    # Resize if needed (preserving binary nature)\n",
        "    if max(img_array.shape[:2]) > MAX_IMAGE_SIZE:\n",
        "        scale = MAX_IMAGE_SIZE / max(img_array.shape[:2])\n",
        "        new_size = (int(img_array.shape[1] * scale), int(img_array.shape[0] * scale))\n",
        "        print(f\"   üîç Resizing from {img_array.shape[1]}x{img_array.shape[0]} to {new_size}\")\n",
        "        img_array = np.array(rgb_img.resize(new_size, Image.NEAREST))\n",
        "\n",
        "    # Show binary preservation\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.array(Image.open(img_path)), cmap='gray')\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_array, cmap='gray')\n",
        "    plt.title('Binary-Preserved Input')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/binary_preservation.png', dpi=150)\n",
        "    print(\"‚úÖ Binary preservation steps visualized in /content/binary_preservation.png\")\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error processing image: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# =====================================================================\n",
        "# INFERENCE (OBB-SPECIFIC)\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîç Inference - OBB Specific Approach\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    print(f\"\\nüîÑ Running inference with conf={DEFAULT_CONF_THRESHOLD}...\")\n",
        "    start = time.time()\n",
        "\n",
        "    # OBB-specific inference\n",
        "    if hasattr(model, 'predict_obb'):\n",
        "        results = model.predict_obb(\n",
        "            img_array,\n",
        "            conf=DEFAULT_CONF_THRESHOLD,\n",
        "            iou=DEFAULT_IOU_THRESHOLD,\n",
        "            imgsz=MAX_IMAGE_SIZE,\n",
        "            verbose=False\n",
        "        )\n",
        "    else:\n",
        "        # Standard prediction with OBB-friendly parameters\n",
        "        results = model.predict(\n",
        "            img_array,\n",
        "            conf=DEFAULT_CONF_THRESHOLD,\n",
        "            iou=DEFAULT_IOU_THRESHOLD,\n",
        "            imgsz=MAX_IMAGE_SIZE,\n",
        "            verbose=False,\n",
        "            save_txt=False\n",
        "        )\n",
        "\n",
        "    inf_time = (time.time() - start) * 1000\n",
        "    result = results[0]\n",
        "    boxes = result.boxes\n",
        "\n",
        "    print(f\"‚úÖ Complete: {inf_time:.1f}ms ({1000.0/inf_time:.1f} FPS)\")\n",
        "    if boxes is not None:\n",
        "        print(f\"   Detections: {len(boxes)}\")\n",
        "    else:\n",
        "        print(f\"   Detections: 0 (No objects detected)\")\n",
        "\n",
        "    # Class counts\n",
        "    if boxes is not None and len(boxes) > 0:\n",
        "        class_counts = {}\n",
        "        for box in boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            name = model.names[cls_id]\n",
        "            class_counts[name] = class_counts.get(name, 0) + 1\n",
        "        print(f\"\\nüìä By Class:\")\n",
        "        for name, count in sorted(class_counts.items()):\n",
        "            print(f\"   {name}: {count}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during inference: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# =====================================================================\n",
        "# VISUALIZATION (BINARY-APPROPRIATE)\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üé® Visualization - Binary Image Compatible\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    # Create visualization with no text labels\n",
        "    plot_result = result.plot(labels=False, line_width=2)\n",
        "\n",
        "    # Create figure with legend\n",
        "    fig = plt.figure(figsize=(22, 10))\n",
        "    gs = fig.add_gridspec(1, 3, width_ratios=[1, 1.2, 0.4])\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0])\n",
        "    ax2 = fig.add_subplot(gs[1])\n",
        "    ax3 = fig.add_subplot(gs[2])\n",
        "\n",
        "    # Original image (binary)\n",
        "    ax1.imshow(np.array(Image.open(img_path)), cmap='gray')\n",
        "    ax1.set_title('Original Binary Diagram', fontsize=14)\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Result with bounding boxes\n",
        "    ax2.imshow(plot_result)\n",
        "    detection_count = len(boxes) if boxes is not None else 0\n",
        "    ax2.set_title(f'Detections: {detection_count} ({inf_time:.0f}ms)', fontsize=14)\n",
        "    ax2.axis('off')\n",
        "\n",
        "    # Legend panel\n",
        "    ax3.axis('off')\n",
        "    legend_elements = []\n",
        "\n",
        "    # Custom high-contrast color palette\n",
        "    colors = [\n",
        "        (255, 0, 0),       # Red\n",
        "        (0, 255, 0),       # Green\n",
        "        (0, 0, 255),       # Blue\n",
        "        (255, 255, 0),     # Yellow\n",
        "        (255, 0, 255),     # Magenta\n",
        "        (0, 255, 255),     # Cyan\n",
        "        (128, 0, 0),       # Maroon\n",
        "        (0, 128, 0),       # Dark Green\n",
        "        (0, 0, 128),       # Navy\n",
        "        (128, 128, 0),     # Olive\n",
        "        (128, 0, 128),     # Purple\n",
        "        (0, 128, 128),     # Teal\n",
        "    ]\n",
        "\n",
        "    # Add legend entries\n",
        "    for cls_id, cls_name in model.names.items():\n",
        "        if cls_id < len(colors):\n",
        "            color = colors[cls_id]\n",
        "            normalized_color = (color[0]/255, color[1]/255, color[2]/255)\n",
        "\n",
        "            # Count detections\n",
        "            count = 0\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    if int(box.cls[0]) == cls_id:\n",
        "                        count += 1\n",
        "\n",
        "            legend_elements.append(Patch(\n",
        "                facecolor=normalized_color,\n",
        "                edgecolor='black',\n",
        "                label=f\"{cls_name} ({count})\"\n",
        "            ))\n",
        "\n",
        "    # Create legend\n",
        "    ax3.legend(\n",
        "        handles=legend_elements,\n",
        "        loc='center',\n",
        "        fontsize=10,\n",
        "        frameon=True,\n",
        "        framealpha=0.95,\n",
        "        title=\"HVAC Components\",\n",
        "        title_fontsize=12,\n",
        "        facecolor='white'\n",
        "    )\n",
        "    ax3.set_title(\"Detection Legend\", fontsize=14, pad=20)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)\n",
        "    plt.savefig('/content/inference_result.png', bbox_inches='tight', dpi=150)\n",
        "    print(\"‚úÖ Visualization saved to /content/inference_result.png\")\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during visualization: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# =====================================================================\n",
        "# CONCLUSION & NEXT STEPS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚úÖ Pipeline Completed Successfully\")\n",
        "print(\"=\"*50)\n",
        "print(f\"üéØ Detections: {detection_count if 'detection_count' in locals() else 0}\")\n",
        "print(f\"‚ö° Time: {inf_time:.1f}ms\")\n",
        "print(f\"üíæ Results saved to: /content/inference_result.png\")\n",
        "\n",
        "# Final recommendations\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîß Critical Next Steps\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. Use ONLY binary images (black lines on white background) for this model\")\n",
        "print(\"2. If your diagrams aren't binary, convert them with:\")\n",
        "print(\"   ‚Ä¢ Use: cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\")\n",
        "print(\"3. Verify your training data was also binary\")\n",
        "print(\"4. For future models, consider RGB training if your source images are color\")\n",
        "print(\"5. If you need grayscale support, retrain with grayscale augmentation\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5a_1AyI5Lju"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "print(\"üöÄ Deploying API Server\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Validate configuration\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(\"\\n‚ùå ERROR: MODEL_PATH not found. Check configuration.\")\n",
        "    raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
        "\n",
        "print(f\"‚úÖ Model found: {MODEL_PATH}\")\n",
        "\n",
        "# Setup ngrok tunnel\n",
        "if NGROK_AUTHTOKEN and NGROK_AUTHTOKEN != \"YOUR_NGROK_TOKEN_HERE\":\n",
        "    print(\"\\nüåê Setting up ngrok tunnel...\")\n",
        "    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "    public_url = ngrok.connect(PORT)\n",
        "    print(f\"\\n‚úÖ API LIVE!\")\n",
        "    print(f\"   Public URL: {public_url.public_url}\")\n",
        "    print(f\"   API Docs: {public_url.public_url}/docs\")\n",
        "    print(f\"   Health: {public_url.public_url}/health\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No ngrok token - server will be local only\")\n",
        "    print(f\"   Local URL: http://localhost:{PORT}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üé¨ Starting server (Press STOP button to shutdown)...\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Validate python-services directory exists\n",
        "if not os.path.exists('python-services'):\n",
        "    print(\"‚ùå ERROR: python-services directory not found\")\n",
        "    print(f\"   Current directory: {os.getcwd()}\")\n",
        "    print(\"   Please ensure you're in the hvac-ai repository root\")\n",
        "    raise FileNotFoundError(\"python-services directory not found\")\n",
        "\n",
        "%cd python-services\n",
        "# Use PORT variable via Python string formatting\n",
        "import subprocess\n",
        "subprocess.run([\"uvicorn\", \"hvac_analysis_service:app\", \"--host\", \"0.0.0.0\", \"--port\", str(PORT), \"--reload\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
