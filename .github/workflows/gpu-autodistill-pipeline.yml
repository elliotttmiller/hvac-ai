# .github/workflows/gpu-autodistill-pipeline.yml
name: HVAC-AI GPU AutoDistill Pipeline

on:
  workflow_dispatch:  # Allows manual triggering
  push:
    branches: [main, dev]
    paths:
      - 'notebooks/**'
      - 'python-services/**'
      - '.github/workflows/gpu-autodistill-pipeline.yml'
  pull_request:
    branches: [main]
    paths:
      - 'notebooks/**'
      - 'python-services/**'

jobs:
  run-gpu-pipeline:
    runs-on: ubuntu-latest
    hardware:
      gpu: T4  # NVIDIA Tesla T4 GPU - good balance of cost/performance
    permissions:
      contents: read
      actions: read
    env:
      PYTHON_VERSION: "3.10"
      CUDA_VERSION: "12.1"
      NVIDIA_DRIVER_VERSION: "535"
      NOTEBOOK_NAME: "autodistill_pipeline.ipynb"  # Update if your notebook has a different name

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            curl \
            libgl1 \
            libsm6 \
            libxrender1 \
            libxext6 \
            libgl1-mesa-glx \
            libglib2.0-0 \
            ffmpeg \
            libgomp1 \
            git \
            wget \
            unzip \
            software-properties-common
            
          # Add NVIDIA repository and install drivers
          sudo apt-get install -y ubuntu-drivers-common
          sudo ubuntu-drivers autoinstall
          
          # Install NVIDIA driver dependencies
          sudo apt-get install -y --no-install-recommends \
            nvidia-driver-${{ env.NVIDIA_DRIVER_VERSION }} \
            nvidia-cuda-toolkit \
            nvidia-utils-${{ env.NVIDIA_DRIVER_VERSION }}

      - name: Verify GPU availability
        run: |
          echo "=== üöÄ GPU ENVIRONMENT VALIDATION ==="
          echo ""
          
          # Check if NVIDIA GPU is detected
          echo "=== NVIDIA GPU DETECTION ==="
          if lspci | grep -i nvidia; then
            echo "‚úÖ NVIDIA GPU detected"
          else
            echo "‚ùå No NVIDIA GPU detected in PCI devices"
          fi
          echo ""
          
          # Check NVIDIA driver installation
          echo "=== NVIDIA DRIVER INFORMATION ==="
          if command -v nvidia-smi &> /dev/null; then
            nvidia-smi
          else
            echo "‚ùå nvidia-smi command not found - driver may not be installed correctly"
          fi
          echo ""
          
          # Check CUDA installation
          echo "=== CUDA VERSION ==="
          if command -v nvcc &> /dev/null; then
            nvcc --version
          else
            echo "‚ùå nvcc not found - CUDA toolkit may not be installed"
          fi
          echo ""

      - name: Install Python dependencies with GPU support
        run: |
          cd python-services
          
          # Create and activate virtual environment
          python -m venv .venv
          source .venv/bin/activate
          
          # Upgrade pip and setuptools
          pip install --upgrade pip setuptools wheel
          
          # Install NVIDIA index for optimized packages
          pip install nvidia-pyindex
          
          # Install CUDA runtime libraries
          pip install nvidia-cuda-runtime-cu12
          
          # Install GPU-enabled PyTorch (CUDA 12.1)
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
          
          # Install AutoDistill ecosystem with GPU support
          pip install autodistill autodistill-grounded-sam autodistill-yolov8 supervision
          
          # Install supporting GPU-accelerated libraries
          pip install opencv-python-headless transformers sentence-transformers ultralytics numpy pandas matplotlib jupyter nbconvert jupyter-client jupyter-core
          
          # Install HVAC-AI specific requirements
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          
          echo "‚úÖ All Python dependencies installed with GPU support"

      - name: Download required model weights
        run: |
          cd python-services
          source .venv/bin/activate
          
          # Create weights directory
          mkdir -p weights
          
          echo "=== üì• DOWNLOADING MODEL WEIGHTS ==="
          
          # Download SAM weights (Segment Anything Model)
          if [ ! -f weights/sam_vit_h_4b8939.pth ]; then
            echo "üì• Downloading SAM weights (large model)..."
            wget -O weights/sam_vit_h_4b8939.pth https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
            echo "‚úÖ SAM weights downloaded successfully"
          else
            echo "‚úÖ SAM weights already exist"
          fi
          
          # Download GroundingDINO weights
          if [ ! -f weights/groundingdino_swint_ogc.pth ]; then
            echo "üì• Downloading GroundingDINO weights..."
            wget -O weights/groundingdino_swint_ogc.pth https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth
            echo "‚úÖ GroundingDINO weights downloaded successfully"
          else
            echo "‚úÖ GroundingDINO weights already exist"
          fi
          
          # Create directory for notebook execution
          mkdir -p ../notebooks/executed
          
          echo "‚úÖ Model weights setup completed"

      - name: Prepare notebook for execution
        run: |
          cd notebooks
          
          # Create execution directory if it doesn't exist
          mkdir -p executed
          
          # Check if notebook exists
          if [ ! -f "${NOTEBOOK_NAME}" ]; then
            echo "‚ùå ERROR: Notebook '${NOTEBOOK_NAME}' not found in notebooks directory"
            echo "Available notebooks:"
            ls -la
            exit 1
          fi
          
          # Copy notebook to execution directory
          cp "${NOTEBOOK_NAME}" executed/
          echo "‚úÖ Notebook copied to execution directory: notebooks/executed/${NOTEBOOK_NAME}"
          
          # Create GPU validation script
          cat > executed/gpu_validation.py << 'EOF'
import torch
import subprocess
import sys
import os

def validate_gpu_environment():
    """Comprehensive GPU environment validation for HVAC-AI AutoDistill pipeline"""
    print("=== üî• HVAC-AI GPU ENVIRONMENT VALIDATION ===")
    
    # Check CUDA availability
    cuda_available = torch.cuda.is_available()
    print(f"‚úÖ CUDA Available: {cuda_available}")
    
    if not cuda_available:
        print("‚ùå FATAL ERROR: CUDA not available. AutoDistill pipeline requires GPU acceleration.")
        print("   Troubleshooting steps:")
        print("   1. Verify NVIDIA drivers are installed (>=535)")
        print("   2. Check CUDA 12.1 toolkit is properly configured")
        print("   3. Run 'nvidia-smi' to verify GPU detection")
        sys.exit(1)
    
    # Get CUDA version from PyTorch
    cuda_version = torch.version.cuda
    print(f"‚úÖ PyTorch CUDA Version: {cuda_version}")
    
    # Get driver version
    try:
        driver_output = subprocess.check_output(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'], stderr=subprocess.DEVNULL)
        driver_version = driver_output.decode().strip()
        print(f"‚úÖ NVIDIA Driver Version: {driver_version}")
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("‚ö†Ô∏è WARNING: Could not verify NVIDIA driver version")
    
    # Check available GPUs and memory
    gpu_count = torch.cuda.device_count()
    print(f"‚úÖ Available GPUs: {gpu_count}")
    
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        total_memory = torch.cuda.get_device_properties(i).total_memory / 1e9  # Convert to GB
        print(f"   GPU {i}: {gpu_name} - {total_memory:.1f}GB VRAM")
        
        # Warning if less than 16GB VRAM
        if total_memory < 16.0:
            print(f"‚ö†Ô∏è WARNING: GPU {i} has only {total_memory:.1f}GB VRAM. HVAC-AI pipeline performs best with 16GB+ VRAM")
    
    # Test CUDA operations
    try:
        print("   Testing CUDA tensor operations...")
        x = torch.rand(1000, 1000, device='cuda')
        y = torch.rand(1000, 1000, device='cuda')
        z = torch.matmul(x, y)
        print("‚úÖ CUDA tensor operations successful")
    except Exception as e:
        print(f"‚ùå CUDA operation failed: {str(e)}")
        print("   Troubleshooting:")
        print("   1. Check for CUDA out-of-memory errors")
        print("   2. Verify CUDA toolkit and driver compatibility")
        sys.exit(1)
    
    # Set CUDA device explicitly
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"‚úÖ Using device: {device}")
    
    return device

# Execute validation
device = validate_gpu_environment()
EOF

          echo "‚úÖ GPU validation script created"

      - name: Execute AutoDistill pipeline notebook
        run: |
          cd notebooks/executed
          
          # Activate virtual environment
          source ../../python-services/.venv/bin/activate
          
          echo "=== üöÄ EXECUTING HVAC-AI AUTODISTILL PIPELINE ==="
          echo "Notebook: $NOTEBOOK_NAME"
          if command -v nvidia-smi &> /dev/null; then
            echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader)"
          else
            echo "GPU: Unknown (nvidia-smi not available)"
          fi
          echo ""
          
          # First validate GPU environment
          echo "=== üîç VALIDATING GPU ENVIRONMENT ==="
          python gpu_validation.py
          
          echo ""
          echo "=== ‚ö° EXECUTING NOTEBOOK WITH GPU ACCELERATION ==="
          
          # Execute notebook with GPU support
          jupyter nbconvert \
            --to notebook \
            --execute "$NOTEBOOK_NAME" \
            --output "executed_$NOTEBOOK_NAME" \
            --ExecutePreprocessor.timeout=7200 \  # 2-hour timeout
            --ExecutePreprocessor.kernel_name=python3 \
            --log-level=DEBUG
          
          echo ""
          echo "=== ‚úÖ NOTEBOOK EXECUTION COMPLETED SUCCESSFULLY ==="
          
          # Display execution summary
          if command -v nvidia-smi &> /dev/null; then
            nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv
          fi

      - name: Upload executed notebook as artifact
        uses: actions/upload-artifact@v4
        with:
          name: executed-notebook-${{ github.sha }}
          path: notebooks/executed/executed_${{ env.NOTEBOOK_NAME }}
          retention-days: 7

      - name: Upload pipeline results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-results-${{ github.sha }}
          path: |
            notebooks/executed/results/
            notebooks/executed/output/
            notebooks/executed/*.json
            notebooks/executed/*.csv
            notebooks/executed/*.png
            notebooks/executed/*.jpg
            notebooks/executed/*.pt
            notebooks/executed/*.pth
            notebooks/executed/*.pkl
          retention-days: 7

      - name: Post-execution cleanup
        if: always()
        run: |
          echo "=== üßπ POST-EXECUTION CLEANUP ==="
          
          # Clear GPU memory
          echo "Clearing GPU memory cache..."
          python -c "import torch; torch.cuda.empty_cache()" || echo "Could not clear GPU cache"
          
          # Display final GPU state
          echo "=== FINAL GPU STATE ==="
          if command -v nvidia-smi &> /dev/null; then
            nvidia-smi
          else
            echo "nvidia-smi not available"
          fi

      - name: Generate execution summary
        if: always()
        run: |
          cat > execution_summary.md << EOF
# HVAC-AI AutoDistill Pipeline Execution Summary

**Workflow:** ${{ github.workflow }}
**Run ID:** ${{ github.run_id }}
**Status:** ${{ job.status }}
**Timestamp:** $(date '+%Y-%m-%d %H:%M:%S UTC')

## GPU Configuration
- **GPU Type:** NVIDIA Tesla T4
- **CUDA Version:** ${{ env.CUDA_VERSION }}
- **Driver Version:** ${{ env.NVIDIA_DRIVER_VERSION }}

## Execution Details
- **Notebook:** ${{ env.NOTEBOOK_NAME }}
- **Repository:** ${{ github.repository }}
- **Branch:** ${{ github.ref_name }}

## Performance Metrics
EOF
          
          # Add GPU metrics if available
          if command -v nvidia-smi &> /dev/null; then
            echo "- **GPU Utilization:** $(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader || echo "N/A")" >> execution_summary.md
            echo "- **GPU Memory Used:** $(nvidia-smi --query-gpu=memory.used --format=csv,noheader || echo "N/A")" >> execution_summary.md
          fi
          
          cat >> execution_summary.md << EOF

## Artifacts Generated
- ‚úÖ Executed notebook with outputs
- ‚úÖ Pipeline results (JSON, CSV, images, model files)
- ‚úÖ Execution summary report

## Next Steps
1. **Download artifacts** from the workflow run
2. **Review the executed notebook** for any errors or warnings
3. **Analyze pipeline results** for HVAC component detection accuracy
4. **Validate model performance** against ground truth data

## Cost Information
- **GPU Runtime:** ~$3.46/hour for T4 GPU
- **Estimated Cost:** Variable based on execution time

---
*This summary was automatically generated by GitHub Actions workflow*
EOF
          
          echo "‚úÖ Execution summary generated"
          
          # Display summary
          cat execution_summary.md

      - name: Upload execution summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: execution-summary-${{ github.sha }}
          path: execution_summary.md
          retention-days: 30

  notify-completion:
    needs: run-gpu-pipeline
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Send completion notification
        run: |
          STATUS="${{ needs.run-gpu-pipeline.result }}"
          
          if [ "$STATUS" = "success" ]; then
            echo "üéâ HVAC-AI AutoDistill pipeline executed successfully!"
            echo "‚úÖ All artifacts have been uploaded and are available for download."
            echo ""
            echo "üìä KEY RESULTS:"
            echo "   - GPU-accelerated component detection completed"
            echo "   - HVAC blueprint analysis successful"
            echo "   - Model outputs saved as artifacts"
          else
            echo "üö® HVAC-AI AutoDistill pipeline execution failed!"
            echo "‚ùå Check the workflow logs for detailed error information."
            echo ""
            echo "üîß COMMON TROUBLESHOOTING STEPS:"
            echo "   - GPU memory exhaustion (OSError: CUDA out of memory)"
            echo "   - CUDA driver compatibility issues"
            echo "   - Missing model weights or dependencies"
            echo "   - Notebook execution timeout (2 hours maximum)"
            echo "   - Incorrect notebook path or name"
          fi
          
          echo ""
          echo "üí∞ COST OPTIMIZATION TIPS:"
          echo "   - T4 GPU: ~$3.46/hour (most cost-effective for development)"
          echo "   - A10G GPU: ~$6.91/hour (faster for production runs)"
          echo "   - L4 GPU: ~$10.37/hour (best for large-scale processing)"
          echo ""
          echo "üí° RECOMMENDATION: Use T4 for development/testing, upgrade to A10G/L4 for production deployments"