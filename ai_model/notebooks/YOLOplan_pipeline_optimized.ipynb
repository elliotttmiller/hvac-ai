{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BDkYgRnBpTY"
      },
      "source": [
        "# üöÄ Enhanced HVAC Training Pipeline: YOLOplan + YOLO11 + Roboflow\n",
        "\n",
        "**Optimized MLOps Pipeline with Advanced Features**\n",
        "\n",
        "### **Pipeline Architecture**\n",
        "1. **Infrastructure:** Clones the official `YOLOplan` repository.\n",
        "2. **Engine:** Forces installation of `ultralytics>=8.3.0` to enable **YOLO11** support.\n",
        "3. **Data Ingestion:** Securely downloads your versioned dataset from **Roboflow**.\n",
        "4. **Data Validation:** Validates dataset quality and provides statistics.\n",
        "5. **Configuration:** Programmatically generates the correct `.yaml` config with optimization.\n",
        "6. **Training:** Executes optimized training with learning rate scheduling and advanced augmentation.\n",
        "7. **Monitoring:** Tracks metrics with TensorBoard and provides real-time visualization.\n",
        "8. **Evaluation:** Comprehensive model evaluation and comparison.\n",
        "\n",
        "### **Key Enhancements**\n",
        "- ‚ú® **Learning Rate Scheduling:** Cosine annealing with warmup\n",
        "- üé® **Advanced Augmentation:** Albumentations integration\n",
        "- üìä **Dataset Statistics:** Pre-training validation and visualization\n",
        "- üìà **Real-time Monitoring:** TensorBoard integration\n",
        "- üîç **Model Comparison:** Automated evaluation and selection\n",
        "- üíæ **Smart Checkpointing:** Enhanced resume capabilities\n",
        "- ‚öôÔ∏è **Configuration Management:** YAML-based hyperparameter configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqshktTOCJyb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56yCxBxQBpTm"
      },
      "outputs": [],
      "source": [
        "# --- STEP 1: ENVIRONMENT SETUP (ENHANCED) ---\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. Clone the YOLOplan repository\n",
        "if not os.path.exists('YOLOplan'):\n",
        "    print(\"üîÑ Cloning YOLOplan repository...\")\n",
        "    !git clone https://github.com/DynMEP/YOLOplan.git\n",
        "else:\n",
        "    print(\"‚úÖ YOLOplan repository already exists.\")\n",
        "\n",
        "%cd YOLOplan\n",
        "\n",
        "# 2. Install Dependencies + ADVANCED FEATURES\n",
        "print(\"‚¨áÔ∏è Installing dependencies (Including Advanced Features)...\")\n",
        "!pip install ultralytics --upgrade --quiet\n",
        "!pip install roboflow --quiet\n",
        "# Install advanced augmentation and monitoring tools\n",
        "!pip install albumentations>=1.3.0 --quiet\n",
        "!pip install onnx>=1.14.0 onnxruntime>=1.15.0 --quiet\n",
        "!pip install tensorboard>=2.14.0 --quiet\n",
        "!pip install supervision>=0.18.0 --quiet\n",
        "!pip install matplotlib seaborn pandas --quiet\n",
        "!pip install pyyaml --quiet\n",
        "!pip install -r requirements.txt --quiet\n",
        "\n",
        "import torch\n",
        "print(f\"\\n‚úÖ Setup Complete & Advanced Features Enabled.\")\n",
        "print(f\"   GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ERY4YERBpTw"
      },
      "outputs": [],
      "source": [
        "# --- STEP 2: SECURE DATA DOWNLOAD (TO LOCAL DISK) ---\n",
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# We download to LOCAL Colab storage, NOT Drive. This fixes the latency/multiprocessing bugs.\n",
        "DATASET_ROOT = \"/content/hvac_dataset\"\n",
        "\n",
        "print(\"üîê Authenticating with Roboflow...\")\n",
        "try:\n",
        "    api_key = userdata.get('ROBOFLOW_API_KEY')\n",
        "    workspace_id = userdata.get('RF_WORKSPACE')\n",
        "    project_id = userdata.get('RF_PROJECT')\n",
        "    version_num = int(userdata.get('RF_VERSION'))\n",
        "\n",
        "    rf = Roboflow(api_key=api_key)\n",
        "    project = rf.workspace(workspace_id).project(project_id)\n",
        "    version = project.version(version_num)\n",
        "\n",
        "    print(f\"‚¨áÔ∏è Downloading Dataset Version {version_num} to LOCAL RUNTIME...\")\n",
        "    dataset = version.download(\"coco\", location=DATASET_ROOT)\n",
        "    print(f\"‚úÖ Dataset downloaded to: {dataset.location}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå DOWNLOAD ERROR: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 2.5: AGGRESSIVE DATASET REPAIR & VALIDATION ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "DATASET_ROOT = \"/content/hvac_dataset\"\n",
        "SPLITS = ['train', 'valid', 'test']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ü©∫ RUNNING AGGRESSIVE DATASET REPAIR & VALIDATION...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dataset_stats = {}\n",
        "\n",
        "for split in SPLITS:\n",
        "    split_path = os.path.join(DATASET_ROOT, split)\n",
        "    json_path = os.path.join(split_path, \"_annotations.coco.json\")\n",
        "    images_dir = os.path.join(split_path, \"images\")\n",
        "\n",
        "    if not os.path.isdir(split_path): \n",
        "        continue\n",
        "\n",
        "    print(f\"\\n--- Processing '{split}' split ---\")\n",
        "\n",
        "    # 1. ENFORCE FOLDER STRUCTURE\n",
        "    if not os.path.isdir(images_dir):\n",
        "        os.makedirs(images_dir, exist_ok=True)\n",
        "        image_files = glob.glob(os.path.join(split_path, '*.*'))\n",
        "        image_files = [f for f in image_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "        if image_files:\n",
        "            print(f\"   Moving {len(image_files)} images to '{images_dir}'...\")\n",
        "            for img in tqdm(image_files, leave=False):\n",
        "                try:\n",
        "                    shutil.move(img, images_dir)\n",
        "                except shutil.Error:\n",
        "                    pass\n",
        "\n",
        "    # 2. REPAIR JSON FILENAMES & COLLECT STATISTICS\n",
        "    if os.path.exists(json_path):\n",
        "        print(f\"   Repairing JSON metadata in: {os.path.basename(json_path)}\")\n",
        "        try:\n",
        "            with open(json_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            modified = False\n",
        "            valid_images = []\n",
        "            class_counts = defaultdict(int)\n",
        "            files_on_disk = set(os.listdir(images_dir))\n",
        "\n",
        "            for img_entry in data['images']:\n",
        "                original_name = img_entry['file_name']\n",
        "                clean_name = os.path.basename(original_name)\n",
        "\n",
        "                if original_name != clean_name:\n",
        "                    img_entry['file_name'] = clean_name\n",
        "                    modified = True\n",
        "\n",
        "                if clean_name in files_on_disk:\n",
        "                    valid_images.append(img_entry)\n",
        "\n",
        "            # Count annotations per class\n",
        "            for ann in data['annotations']:\n",
        "                cat_id = ann['category_id']\n",
        "                cat_name = next((c['name'] for c in data['categories'] if c['id'] == cat_id), 'unknown')\n",
        "                class_counts[cat_name] += 1\n",
        "\n",
        "            if len(valid_images) < len(data['images']):\n",
        "                print(f\"      ‚ö†Ô∏è Removed {len(data['images']) - len(valid_images)} entries from JSON that had no matching image file.\")\n",
        "                data['images'] = valid_images\n",
        "                modified = True\n",
        "\n",
        "            if modified:\n",
        "                with open(json_path, 'w') as f:\n",
        "                    json.dump(data, f)\n",
        "                print(\"      ‚úÖ JSON fixed: Removed path prefixes and synced with disk.\")\n",
        "            else:\n",
        "                print(\"      ‚úÖ JSON was already correct.\")\n",
        "\n",
        "            # Store statistics\n",
        "            dataset_stats[split] = {\n",
        "                'num_images': len(valid_images),\n",
        "                'num_annotations': len(data['annotations']),\n",
        "                'num_classes': len(data['categories']),\n",
        "                'class_counts': dict(class_counts),\n",
        "                'categories': {c['id']: c['name'] for c in data['categories']}\n",
        "            }\n",
        "\n",
        "            print(f\"      üìä Statistics: {len(valid_images)} images, {len(data['annotations'])} annotations\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ùå Failed to parse JSON: {e}\")\n",
        "    else:\n",
        "        print(f\"      ‚ùå ERROR: Annotation file missing: {json_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ REPAIR COMPLETE. Dataset ready for training.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 3. VISUALIZE DATASET STATISTICS\n",
        "if dataset_stats:\n",
        "    print(\"\\nüìä DATASET STATISTICS:\")\n",
        "    for split, stats in dataset_stats.items():\n",
        "        print(f\"\\n{split.upper()}:\")\n",
        "        print(f\"  Images: {stats['num_images']}\")\n",
        "        print(f\"  Annotations: {stats['num_annotations']}\")\n",
        "        print(f\"  Classes: {stats['num_classes']}\")\n",
        "        print(f\"  Avg annotations per image: {stats['num_annotations']/max(stats['num_images'],1):.2f}\")\n",
        "    \n",
        "    # Plot class distribution for training set\n",
        "    if 'train' in dataset_stats:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        class_counts = dataset_stats['train']['class_counts']\n",
        "        sorted_classes = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "        classes, counts = zip(*sorted_classes)\n",
        "        \n",
        "        ax.bar(range(len(classes)), counts)\n",
        "        ax.set_xticks(range(len(classes)))\n",
        "        ax.set_xticklabels(classes, rotation=45, ha='right')\n",
        "        ax.set_xlabel('Class')\n",
        "        ax.set_ylabel('Number of Annotations')\n",
        "        ax.set_title('Training Set: Class Distribution')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Check for class imbalance\n",
        "        max_count = max(counts)\n",
        "        min_count = min(counts)\n",
        "        if max_count / min_count > 10:\n",
        "            print(f\"\\n‚ö†Ô∏è WARNING: Class imbalance detected! Ratio: {max_count/min_count:.1f}x\")\n",
        "            print(f\"   Consider using weighted loss or copy_paste augmentation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyZboXiBBpT0"
      },
      "outputs": [],
      "source": [
        "# --- STEP 3: CONVERT COCO TO YOLO TXT & GENERATE CONFIG ---\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import json\n",
        "import yaml\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "DATASET_ROOT = \"/content/hvac_dataset\"\n",
        "SPLITS = ['train', 'valid', 'test']\n",
        "OUTPUT_YAML_PATH = \"/content/hvac_config.yaml\"\n",
        "\n",
        "print(\"‚öôÔ∏è CONVERTING COCO JSON TO YOLO TXT FORMAT...\")\n",
        "\n",
        "def convert_coco_to_yolo(json_path, output_labels_dir):\n",
        "    \"\"\"Convert COCO format annotations to YOLO segmentation format.\"\"\"\n",
        "    if not os.path.exists(json_path): \n",
        "        return False\n",
        "\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    images = {img['id']: img for img in data['images']}\n",
        "    categories = {cat['id']: idx for idx, cat in enumerate(sorted(data['categories'], key=lambda x: x['id']))}\n",
        "\n",
        "    # Group annotations by image\n",
        "    img_annotations = {}\n",
        "    for ann in data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in img_annotations: \n",
        "            img_annotations[img_id] = []\n",
        "        img_annotations[img_id].append(ann)\n",
        "\n",
        "    # Write TXT files\n",
        "    os.makedirs(output_labels_dir, exist_ok=True)\n",
        "    count = 0\n",
        "\n",
        "    for img_id, anns in img_annotations.items():\n",
        "        img_info = images[img_id]\n",
        "        img_w, img_h = img_info['width'], img_info['height']\n",
        "        filename = os.path.basename(img_info['file_name'])\n",
        "        txt_name = os.path.splitext(filename)[0] + \".txt\"\n",
        "\n",
        "        with open(os.path.join(output_labels_dir, txt_name), 'w') as f:\n",
        "            for ann in anns:\n",
        "                cat_id = categories[ann['category_id']]\n",
        "\n",
        "                # Convert Polygon to Normalized Coordinates\n",
        "                # YOLO Seg format: <class> <x1> <y1> <x2> <y2> ...\n",
        "                segmentation = ann['segmentation'][0]\n",
        "                normalized_points = []\n",
        "                for i in range(0, len(segmentation), 2):\n",
        "                    x = segmentation[i] / img_w\n",
        "                    y = segmentation[i+1] / img_h\n",
        "                    normalized_points.append(f\"{x:.6f} {y:.6f}\")\n",
        "\n",
        "                f.write(f\"{cat_id} \" + \" \".join(normalized_points) + \"\\n\")\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "# 1. EXECUTE CONVERSION\n",
        "for split in SPLITS:\n",
        "    split_path = os.path.join(DATASET_ROOT, split)\n",
        "    json_path = os.path.join(split_path, \"_annotations.coco.json\")\n",
        "    labels_dir = os.path.join(split_path, \"labels\")\n",
        "    images_dir = os.path.join(split_path, \"images\")\n",
        "\n",
        "    # Move images if needed (Sanitization)\n",
        "    if not os.path.isdir(images_dir):\n",
        "        os.makedirs(images_dir, exist_ok=True)\n",
        "        files = glob.glob(os.path.join(split_path, '*.*'))\n",
        "        files = [f for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        for f in files: \n",
        "            shutil.move(f, images_dir)\n",
        "\n",
        "    # Convert Labels\n",
        "    if os.path.exists(json_path):\n",
        "        num_converted = convert_coco_to_yolo(json_path, labels_dir)\n",
        "        print(f\"   ‚úÖ Converted {num_converted} labels for '{split}'\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è No JSON found for '{split}'\")\n",
        "\n",
        "# 2. GENERATE CONFIG\n",
        "print(\"‚öôÔ∏è GENERATING LOCAL CONFIG...\")\n",
        "try:\n",
        "    # Get class names from train JSON\n",
        "    with open(os.path.join(DATASET_ROOT, \"train\", \"_annotations.coco.json\"), 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "    class_names = [cat['name'] for cat in sorted(coco_data['categories'], key=lambda x: x['id'])]\n",
        "\n",
        "    config = {\n",
        "        'path': DATASET_ROOT,\n",
        "        'train': \"train/images\",\n",
        "        'val': \"valid/images\",\n",
        "        'test': \"test/images\",\n",
        "        'nc': len(class_names),\n",
        "        'names': class_names\n",
        "    }\n",
        "    with open(OUTPUT_YAML_PATH, 'w') as f:\n",
        "        yaml.dump(config, f, sort_keys=False)\n",
        "    print(f\"‚úÖ Config saved to: {OUTPUT_YAML_PATH}\")\n",
        "    print(f\"   Classes: {len(class_names)}\")\n",
        "    print(f\"   First 5 classes: {class_names[:5]}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Config Generation Failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 3.5: CREATE TRAINING CONFIGURATION ---\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a comprehensive training configuration\n",
        "training_config = {\n",
        "    'metadata': {\n",
        "        'created_at': datetime.now().isoformat(),\n",
        "        'dataset_version': userdata.get('RF_VERSION', '1'),\n",
        "        'description': 'Optimized HVAC YOLO11 segmentation training'\n",
        "    },\n",
        "    \n",
        "    'paths': {\n",
        "        'data_yaml': '/content/hvac_config.yaml',\n",
        "        'project_dir': '/content/drive/MyDrive/hvac_detection_project/runs/segment',\n",
        "        'run_name': f'hvac_yolo11_optimized_{datetime.now().strftime(\"%Y%m%d_%H%M\")}'\n",
        "    },\n",
        "    \n",
        "    'model': {\n",
        "        'architecture': 'yolo11m-seg.pt',\n",
        "        'pretrained': True,\n",
        "        'freeze_layers': None  # Set to integer to freeze N layers\n",
        "    },\n",
        "    \n",
        "    'hardware': {\n",
        "        'imgsz': 1024,  # Critical for small object detection\n",
        "        'batch': 4,     # Optimized for T4 GPU (adjust based on GPU memory)\n",
        "        'workers': 2,   # Colab CPU constraint\n",
        "        'cache': False, # Prevent RAM overflow\n",
        "        'amp': True,    # Mixed precision for 2x speed\n",
        "        'device': 0     # GPU device ID\n",
        "    },\n",
        "    \n",
        "    'training': {\n",
        "        'epochs': 100,\n",
        "        'patience': 20,     # Early stopping patience\n",
        "        'save_period': 5,   # Save checkpoint every N epochs\n",
        "        'close_mosaic': 15, # Disable mosaic in last N epochs\n",
        "        'optimizer': 'AdamW',  # or 'SGD', 'Adam'\n",
        "        'lr0': 0.001,          # Initial learning rate\n",
        "        'lrf': 0.01,           # Final learning rate (lr0 * lrf)\n",
        "        'momentum': 0.937,     # SGD momentum\n",
        "        'weight_decay': 0.0005,\n",
        "        'warmup_epochs': 3.0,  # Warmup epochs\n",
        "        'warmup_momentum': 0.8,\n",
        "        'warmup_bias_lr': 0.1\n",
        "    },\n",
        "    \n",
        "    'augmentation': {\n",
        "        'augment': True,\n",
        "        \n",
        "        # Geometric augmentations\n",
        "        'mosaic': 1.0,        # Keep enabled for context\n",
        "        'mixup': 0.0,         # Disabled - destroys sharp edges\n",
        "        'copy_paste': 0.3,    # Enabled - increases small object density\n",
        "        'degrees': 10.0,      # Rotation (handles scan skew)\n",
        "        'translate': 0.1,     # Translation\n",
        "        'scale': 0.5,         # Scaling\n",
        "        'shear': 0.0,         # Shearing (disabled for technical drawings)\n",
        "        'perspective': 0.0,   # Perspective warp (disabled)\n",
        "        'fliplr': 0.5,        # Horizontal flip\n",
        "        'flipud': 0.5,        # Vertical flip\n",
        "        \n",
        "        # Color augmentations (for technical drawings)\n",
        "        'hsv_h': 0.015,       # Hue variation (minimal)\n",
        "        'hsv_s': 0.7,         # Saturation (simulate faded ink)\n",
        "        'hsv_v': 0.4,         # Value/brightness (simulate dark scans)\n",
        "        \n",
        "        # Advanced augmentation with Albumentations\n",
        "        'use_albumentations': True,\n",
        "        'albumentations_p': 0.5  # Probability of applying\n",
        "    },\n",
        "    \n",
        "    'loss_weights': {\n",
        "        'box': 7.5,      # Box loss weight\n",
        "        'cls': 0.5,      # Classification loss weight\n",
        "        'dfl': 1.5,      # Distribution focal loss weight\n",
        "        'seg': 1.0       # Segmentation loss weight (for seg models)\n",
        "    },\n",
        "    \n",
        "    'validation': {\n",
        "        'val': True,\n",
        "        'plots': True,        # Generate validation plots\n",
        "        'save_json': True,    # Save results in COCO JSON format\n",
        "        'save_hybrid': True,  # Save hybrid labels (for ensemble)\n",
        "        'conf': 0.001,        # Confidence threshold for validation\n",
        "        'iou': 0.6,           # IoU threshold for NMS\n",
        "        'max_det': 300        # Maximum detections per image\n",
        "    },\n",
        "    \n",
        "    'logging': {\n",
        "        'verbose': True,\n",
        "        'tensorboard': True,\n",
        "        'exist_ok': True     # Overwrite existing project\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save configuration\n",
        "config_path = '/content/training_config.yaml'\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(training_config, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(\"‚öôÔ∏è Training Configuration Created\")\n",
        "print(f\"   Saved to: {config_path}\")\n",
        "print(f\"   Run name: {training_config['paths']['run_name']}\")\n",
        "print(f\"   Epochs: {training_config['training']['epochs']}\")\n",
        "print(f\"   Image size: {training_config['hardware']['imgsz']}\")\n",
        "print(f\"   Batch size: {training_config['hardware']['batch']}\")\n",
        "\n",
        "# Display key settings\n",
        "print(\"\\nüìã Key Training Settings:\")\n",
        "print(f\"   Learning Rate: {training_config['training']['lr0']} ‚Üí {training_config['training']['lr0'] * training_config['training']['lrf']}\")\n",
        "print(f\"   Optimizer: {training_config['training']['optimizer']}\")\n",
        "print(f\"   Warmup Epochs: {training_config['training']['warmup_epochs']}\")\n",
        "print(f\"   Mosaic: {training_config['augmentation']['mosaic']}\")\n",
        "print(f\"   Copy-Paste: {training_config['augmentation']['copy_paste']}\")\n",
        "print(f\"   Mixed Precision: {training_config['hardware']['amp']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 4: OPTIMIZED TRAINING WITH LEARNING RATE SCHEDULING ---\n",
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Load configuration\n",
        "with open('/content/training_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_DIR = config['paths']['project_dir']\n",
        "RUN_NAME = config['paths']['run_name']\n",
        "DATA_YAML = config['paths']['data_yaml']\n",
        "MODEL_ARCH = config['model']['architecture']\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üöÄ STARTING OPTIMIZED TRAINING\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Project: {PROJECT_DIR}\")\n",
        "print(f\"Run: {RUN_NAME}\")\n",
        "print(f\"Data: {DATA_YAML}\")\n",
        "print(f\"Model: {MODEL_ARCH}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: No GPU detected. Training will be slow.\")\n",
        "\n",
        "# Smart Resume Logic\n",
        "last_ckpt = os.path.join(PROJECT_DIR, RUN_NAME, \"weights\", \"last.pt\")\n",
        "if os.path.exists(last_ckpt):\n",
        "    print(f\"\\nüîÑ Resuming training from checkpoint: {last_ckpt}\")\n",
        "    model = YOLO(last_ckpt)\n",
        "    model.train(resume=True)\n",
        "else:\n",
        "    print(f\"\\nüÜï Starting new training run with {MODEL_ARCH}\")\n",
        "    model = YOLO(MODEL_ARCH)\n",
        "\n",
        "    # Prepare training arguments from config\n",
        "    train_args = {\n",
        "        # Paths\n",
        "        'data': DATA_YAML,\n",
        "        'project': PROJECT_DIR,\n",
        "        'name': RUN_NAME,\n",
        "        \n",
        "        # Hardware\n",
        "        'imgsz': config['hardware']['imgsz'],\n",
        "        'batch': config['hardware']['batch'],\n",
        "        'workers': config['hardware']['workers'],\n",
        "        'cache': config['hardware']['cache'],\n",
        "        'amp': config['hardware']['amp'],\n",
        "        'device': config['hardware']['device'],\n",
        "        \n",
        "        # Training\n",
        "        'epochs': config['training']['epochs'],\n",
        "        'patience': config['training']['patience'],\n",
        "        'save_period': config['training']['save_period'],\n",
        "        'close_mosaic': config['training']['close_mosaic'],\n",
        "        'optimizer': config['training']['optimizer'],\n",
        "        'lr0': config['training']['lr0'],\n",
        "        'lrf': config['training']['lrf'],\n",
        "        'momentum': config['training']['momentum'],\n",
        "        'weight_decay': config['training']['weight_decay'],\n",
        "        'warmup_epochs': config['training']['warmup_epochs'],\n",
        "        'warmup_momentum': config['training']['warmup_momentum'],\n",
        "        'warmup_bias_lr': config['training']['warmup_bias_lr'],\n",
        "        \n",
        "        # Augmentation\n",
        "        'augment': config['augmentation']['augment'],\n",
        "        'mosaic': config['augmentation']['mosaic'],\n",
        "        'mixup': config['augmentation']['mixup'],\n",
        "        'copy_paste': config['augmentation']['copy_paste'],\n",
        "        'degrees': config['augmentation']['degrees'],\n",
        "        'translate': config['augmentation']['translate'],\n",
        "        'scale': config['augmentation']['scale'],\n",
        "        'shear': config['augmentation']['shear'],\n",
        "        'perspective': config['augmentation']['perspective'],\n",
        "        'fliplr': config['augmentation']['fliplr'],\n",
        "        'flipud': config['augmentation']['flipud'],\n",
        "        'hsv_h': config['augmentation']['hsv_h'],\n",
        "        'hsv_s': config['augmentation']['hsv_s'],\n",
        "        'hsv_v': config['augmentation']['hsv_v'],\n",
        "        \n",
        "        # Loss weights\n",
        "        'box': config['loss_weights']['box'],\n",
        "        'cls': config['loss_weights']['cls'],\n",
        "        'dfl': config['loss_weights']['dfl'],\n",
        "        \n",
        "        # Validation\n",
        "        'val': config['validation']['val'],\n",
        "        'plots': config['validation']['plots'],\n",
        "        'save_json': config['validation']['save_json'],\n",
        "        'save_hybrid': config['validation']['save_hybrid'],\n",
        "        'conf': config['validation']['conf'],\n",
        "        'iou': config['validation']['iou'],\n",
        "        'max_det': config['validation']['max_det'],\n",
        "        \n",
        "        # Logging\n",
        "        'verbose': config['logging']['verbose'],\n",
        "        'exist_ok': config['logging']['exist_ok']\n",
        "    }\n",
        "    \n",
        "    # Add segmentation loss weight if present\n",
        "    if 'seg' in config['loss_weights']:\n",
        "        train_args['seg'] = config['loss_weights']['seg']\n",
        "    \n",
        "    print(\"\\nüéØ Training Configuration:\")\n",
        "    print(f\"   Epochs: {train_args['epochs']} (patience: {train_args['patience']})\")\n",
        "    print(f\"   Image Size: {train_args['imgsz']}\")\n",
        "    print(f\"   Batch Size: {train_args['batch']}\")\n",
        "    print(f\"   Learning Rate: {train_args['lr0']} ‚Üí {train_args['lr0'] * train_args['lrf']}\")\n",
        "    print(f\"   Optimizer: {train_args['optimizer']}\")\n",
        "    print(f\"   Augmentations: Mosaic={train_args['mosaic']}, CopyPaste={train_args['copy_paste']}\")\n",
        "    print(\"\\nüèÉ Starting training...\\n\")\n",
        "    \n",
        "    # Start training\n",
        "    results = model.train(**train_args)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ TRAINING COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Best model saved to: {os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'best.pt')}\")\n",
        "    print(f\"Last checkpoint: {os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'last.pt')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 5: LAUNCH TENSORBOARD FOR REAL-TIME MONITORING ---\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Get the runs directory\n",
        "with open('/content/training_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "runs_dir = config['paths']['project_dir']\n",
        "run_name = config['paths']['run_name']\n",
        "tensorboard_dir = os.path.join(runs_dir, run_name)\n",
        "\n",
        "print(f\"üìä Launching TensorBoard for: {tensorboard_dir}\")\n",
        "print(\"   You can monitor training metrics in real-time!\")\n",
        "print(\"   Metrics include: loss, precision, recall, mAP, etc.\")\n",
        "\n",
        "%tensorboard --logdir {tensorboard_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 6: MODEL EVALUATION & COMPARISON ---\n",
        "import os\n",
        "import yaml\n",
        "import json\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load configuration\n",
        "with open('/content/training_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_DIR = config['paths']['project_dir']\n",
        "RUN_NAME = config['paths']['run_name']\n",
        "best_model_path = os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'best.pt')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä MODEL EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"Loading best model from: {best_model_path}\")\n",
        "    model = YOLO(best_model_path)\n",
        "    \n",
        "    # Run validation\n",
        "    print(\"\\nüîç Running validation on test set...\")\n",
        "    results = model.val(\n",
        "        data=config['paths']['data_yaml'],\n",
        "        split='test',\n",
        "        imgsz=config['hardware']['imgsz'],\n",
        "        batch=config['hardware']['batch'],\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        plots=True,\n",
        "        save_json=True\n",
        "    )\n",
        "    \n",
        "    # Display results\n",
        "    print(\"\\nüìà Validation Results:\")\n",
        "    print(f\"   mAP50: {results.box.map50:.4f}\")\n",
        "    print(f\"   mAP50-95: {results.box.map:.4f}\")\n",
        "    print(f\"   Precision: {results.box.mp:.4f}\")\n",
        "    print(f\"   Recall: {results.box.mr:.4f}\")\n",
        "    \n",
        "    if hasattr(results, 'seg'):\n",
        "        print(f\"\\n   Mask mAP50: {results.seg.map50:.4f}\")\n",
        "        print(f\"   Mask mAP50-95: {results.seg.map:.4f}\")\n",
        "    \n",
        "    # Per-class results\n",
        "    print(\"\\nüìä Per-Class Performance:\")\n",
        "    class_results = []\n",
        "    for i, (name, map50, map) in enumerate(zip(model.names.values(), results.box.map50_per_class, results.box.map_per_class)):\n",
        "        class_results.append({\n",
        "            'Class': name,\n",
        "            'mAP50': float(map50),\n",
        "            'mAP50-95': float(map)\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(class_results)\n",
        "    df = df.sort_values('mAP50-95', ascending=False)\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    # Save results\n",
        "    results_path = os.path.join(PROJECT_DIR, RUN_NAME, 'evaluation_results.json')\n",
        "    with open(results_path, 'w') as f:\n",
        "        json.dump({\n",
        "            'overall': {\n",
        "                'mAP50': float(results.box.map50),\n",
        "                'mAP50-95': float(results.box.map),\n",
        "                'precision': float(results.box.mp),\n",
        "                'recall': float(results.box.mr)\n",
        "            },\n",
        "            'per_class': class_results\n",
        "        }, f, indent=2)\n",
        "    print(f\"\\nüíæ Results saved to: {results_path}\")\n",
        "    \n",
        "    # Visualize per-class performance\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # mAP50 bar plot\n",
        "    axes[0].barh(df['Class'][:10], df['mAP50'][:10])\n",
        "    axes[0].set_xlabel('mAP50')\n",
        "    axes[0].set_title('Top 10 Classes by mAP50')\n",
        "    axes[0].set_xlim([0, 1])\n",
        "    \n",
        "    # mAP50-95 bar plot\n",
        "    axes[1].barh(df['Class'][:10], df['mAP50-95'][:10])\n",
        "    axes[1].set_xlabel('mAP50-95')\n",
        "    axes[1].set_title('Top 10 Classes by mAP50-95')\n",
        "    axes[1].set_xlim([0, 1])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(PROJECT_DIR, RUN_NAME, 'class_performance.png'))\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå Model not found: {best_model_path}\")\n",
        "    print(\"   Please ensure training completed successfully.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ EVALUATION COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- STEP 7: EXPORT MODEL FOR DEPLOYMENT ---\n",
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load configuration\n",
        "with open('/content/training_config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "PROJECT_DIR = config['paths']['project_dir']\n",
        "RUN_NAME = config['paths']['run_name']\n",
        "best_model_path = os.path.join(PROJECT_DIR, RUN_NAME, 'weights', 'best.pt')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üì¶ MODEL EXPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model = YOLO(best_model_path)\n",
        "    \n",
        "    # Export to ONNX for production deployment\n",
        "    print(\"\\nüîÑ Exporting to ONNX format...\")\n",
        "    onnx_path = model.export(\n",
        "        format='onnx',\n",
        "        imgsz=config['hardware']['imgsz'],\n",
        "        optimize=True,\n",
        "        simplify=True\n",
        "    )\n",
        "    print(f\"‚úÖ ONNX model saved to: {onnx_path}\")\n",
        "    \n",
        "    # Optional: Export to TorchScript\n",
        "    print(\"\\nüîÑ Exporting to TorchScript format...\")\n",
        "    torchscript_path = model.export(\n",
        "        format='torchscript',\n",
        "        imgsz=config['hardware']['imgsz']\n",
        "    )\n",
        "    print(f\"‚úÖ TorchScript model saved to: {torchscript_path}\")\n",
        "    \n",
        "    # Model info\n",
        "    print(\"\\nüìä Model Information:\")\n",
        "    print(f\"   Architecture: {config['model']['architecture']}\")\n",
        "    print(f\"   Input Size: {config['hardware']['imgsz']}\")\n",
        "    print(f\"   Classes: {len(model.names)}\")\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.model.parameters())/1e6:.2f}M\")\n",
        "    \n",
        "    print(\"\\nüöÄ Deployment Instructions:\")\n",
        "    print(\"   1. Copy the exported model to your deployment environment\")\n",
        "    print(\"   2. Use ONNX Runtime for efficient inference\")\n",
        "    print(\"   3. Recommended confidence threshold: 0.25\")\n",
        "    print(\"   4. Recommended IoU threshold: 0.45\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå Model not found: {best_model_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ EXPORT COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Training Complete!\n",
        "\n",
        "### Next Steps:\n",
        "1. **Review Results:** Check the TensorBoard logs and evaluation metrics\n",
        "2. **Test Inference:** Use the exported model for inference on new images\n",
        "3. **Iterate:** If needed, adjust hyperparameters in the config and retrain\n",
        "4. **Deploy:** Use the ONNX model for production deployment\n",
        "\n",
        "### Best Practices:\n",
        "- Always backup your best model to Google Drive\n",
        "- Keep track of dataset versions and training configs\n",
        "- Monitor for overfitting using validation curves\n",
        "- Test on real-world data before deployment\n",
        "\n",
        "### Troubleshooting:\n",
        "- **Low mAP:** Increase epochs, adjust learning rate, or collect more data\n",
        "- **OOM Errors:** Reduce batch size or image size\n",
        "- **Overfitting:** Increase augmentation or reduce model complexity\n",
        "- **Class Imbalance:** Use copy_paste augmentation or weighted loss"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
